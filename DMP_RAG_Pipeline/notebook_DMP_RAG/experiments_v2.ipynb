{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0f6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 10/08/2025\n"
     ]
    }
   ],
   "source": [
    "print (\"Start 10/08/2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb52b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ STEP 1 ready\n",
      "ROOT_DIR   : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "DATA_PDFS  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion\n",
      "INDEX_DIR  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss_index\n",
      "EXCEL_PATH : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "TEMPLATE_MD: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n",
      "OUTPUT_MD  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "OUTPUT_DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\n",
      "EMBED_MODEL: sentence-transformers/all-MiniLM-L6-v2 | LLM_MODEL: llama3.3 | TOP_K: 6\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1 — Imports, Config, and Helpers\n",
    "# ============================================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pypandoc  # for Markdown → DOCX\n",
    "\n",
    "# --- LangChain Core ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Paths (works in notebook or script) ----------\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parents[1]  # when running a .py script\n",
    "except NameError:\n",
    "    ROOT_DIR = Path.cwd().parent                     # when running inside Jupyter\n",
    "\n",
    "# --- Data folders ---\n",
    "DATA_PDFS   = ROOT_DIR / \"data\" / \"general_web_ingestion\"\n",
    "INDEX_DIR   = ROOT_DIR / \"data\" / \"faiss_index\"\n",
    "EXCEL_PATH  = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "TEMPLATE_MD = ROOT_DIR / \"data\" / \"inputs\" / \"dmp-template.md\"\n",
    "\n",
    "# --- Output folders ---\n",
    "OUTPUT_MD   = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "OUTPUT_DOCX = ROOT_DIR / \"data\" / \"outputs\" / \"docx\"\n",
    "\n",
    "# --- Models / parameters ---\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LLM_MODEL   = \"llama3.3\"\n",
    "TOP_K       = 6\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def create_folder(folderpath):\n",
    "    Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath, filename, text):\n",
    "    create_folder(folderpath)\n",
    "    (Path(folderpath) / filename).write_text(text, encoding=\"utf-8\")\n",
    "    print(\"💾 Saved:\", Path(folderpath) / filename)\n",
    "\n",
    "def md_to_docs(md_filepath, docx_folderpath, docx_filename):\n",
    "    create_folder(docx_folderpath)\n",
    "    pypandoc.convert_file(\n",
    "        str(md_filepath), \"docx\",\n",
    "        outputfile=str(Path(docx_folderpath) / docx_filename)\n",
    "    )\n",
    "    print(\"📄 Converted:\", Path(docx_folderpath) / docx_filename)\n",
    "\n",
    "def clean_filename(name: str) -> str:\n",
    "    \"\"\"Remove illegal characters from filenames (Windows-safe).\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\n",
    "\n",
    "# ---------- Ensure required folders exist ----------\n",
    "for p in [DATA_PDFS, INDEX_DIR, OUTPUT_MD, OUTPUT_DOCX]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Sanity print ----------\n",
    "print(\"✅ STEP 1 ready\")\n",
    "print(f\"ROOT_DIR   : {ROOT_DIR}\")\n",
    "print(f\"DATA_PDFS  : {DATA_PDFS}\")\n",
    "print(f\"INDEX_DIR  : {INDEX_DIR}\")\n",
    "print(f\"EXCEL_PATH : {EXCEL_PATH}\")\n",
    "print(f\"TEMPLATE_MD: {TEMPLATE_MD}\")\n",
    "print(f\"OUTPUT_MD  : {OUTPUT_MD}\")\n",
    "print(f\"OUTPUT_DOCX: {OUTPUT_DOCX}\")\n",
    "print(f\"EMBED_MODEL: {EMBED_MODEL} | LLM_MODEL: {LLM_MODEL} | TOP_K: {TOP_K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687935b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   5%|▌         | 556/10445 [04:35<2:02:09,  1.35it/s]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 36 65536 (offset 0)\n",
      "Ignoring wrong pointing object 51 65536 (offset 0)\n",
      "Ignoring wrong pointing object 65 65536 (offset 0)\n",
      "Ignoring wrong pointing object 68 65536 (offset 0)\n",
      "Ignoring wrong pointing object 71 65536 (offset 0)\n",
      "Ignoring wrong pointing object 74 65536 (offset 0)\n",
      "Ignoring wrong pointing object 77 65536 (offset 0)\n",
      "Ignoring wrong pointing object 80 65536 (offset 0)\n",
      "Ignoring wrong pointing object 83 65536 (offset 0)\n",
      "Ignoring wrong pointing object 86 65536 (offset 0)\n",
      "Ignoring wrong pointing object 89 65536 (offset 0)\n",
      "Ignoring wrong pointing object 92 65536 (offset 0)\n",
      "Ignoring wrong pointing object 95 65536 (offset 0)\n",
      "Ignoring wrong pointing object 98 65536 (offset 0)\n",
      "Ignoring wrong pointing object 101 65536 (offset 0)\n",
      "Ignoring wrong pointing object 107 65536 (offset 0)\n",
      "Ignoring wrong pointing object 110 65536 (offset 0)\n",
      "Ignoring wrong pointing object 113 65536 (offset 0)\n",
      "Ignoring wrong pointing object 116 65536 (offset 0)\n",
      "Ignoring wrong pointing object 127 65536 (offset 0)\n",
      "Ignoring wrong pointing object 130 65536 (offset 0)\n",
      "Ignoring wrong pointing object 133 65536 (offset 0)\n",
      "Ignoring wrong pointing object 136 65536 (offset 0)\n",
      "Ignoring wrong pointing object 139 65536 (offset 0)\n",
      "Ignoring wrong pointing object 142 65536 (offset 0)\n",
      "Ignoring wrong pointing object 145 65536 (offset 0)\n",
      "Ignoring wrong pointing object 148 65536 (offset 0)\n",
      "Ignoring wrong pointing object 151 65536 (offset 0)\n",
      "Ignoring wrong pointing object 154 65536 (offset 0)\n",
      "Ignoring wrong pointing object 157 65536 (offset 0)\n",
      "Ignoring wrong pointing object 160 65536 (offset 0)\n",
      "Ignoring wrong pointing object 163 65536 (offset 0)\n",
      "Ignoring wrong pointing object 166 65536 (offset 0)\n",
      "Ignoring wrong pointing object 169 65536 (offset 0)\n",
      "Ignoring wrong pointing object 172 65536 (offset 0)\n",
      "Ignoring wrong pointing object 175 65536 (offset 0)\n",
      "Ignoring wrong pointing object 178 65536 (offset 0)\n",
      "Ignoring wrong pointing object 181 65536 (offset 0)\n",
      "Ignoring wrong pointing object 184 65536 (offset 0)\n",
      "Ignoring wrong pointing object 187 65536 (offset 0)\n",
      "Ignoring wrong pointing object 190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 193 65536 (offset 0)\n",
      "Ignoring wrong pointing object 196 65536 (offset 0)\n",
      "Ignoring wrong pointing object 199 65536 (offset 0)\n",
      "Ignoring wrong pointing object 203 65536 (offset 0)\n",
      "Ignoring wrong pointing object 206 65536 (offset 0)\n",
      "Ignoring wrong pointing object 209 65536 (offset 0)\n",
      "Ignoring wrong pointing object 212 65536 (offset 0)\n",
      "Ignoring wrong pointing object 215 65536 (offset 0)\n",
      "Ignoring wrong pointing object 218 65536 (offset 0)\n",
      "Ignoring wrong pointing object 221 65536 (offset 0)\n",
      "Ignoring wrong pointing object 224 65536 (offset 0)\n",
      "Ignoring wrong pointing object 227 65536 (offset 0)\n",
      "Ignoring wrong pointing object 230 65536 (offset 0)\n",
      "Ignoring wrong pointing object 233 65536 (offset 0)\n",
      "Ignoring wrong pointing object 236 65536 (offset 0)\n",
      "Ignoring wrong pointing object 239 65536 (offset 0)\n",
      "Ignoring wrong pointing object 242 65536 (offset 0)\n",
      "Ignoring wrong pointing object 245 65536 (offset 0)\n",
      "Ignoring wrong pointing object 248 65536 (offset 0)\n",
      "Ignoring wrong pointing object 251 65536 (offset 0)\n",
      "Ignoring wrong pointing object 254 65536 (offset 0)\n",
      "Ignoring wrong pointing object 257 65536 (offset 0)\n",
      "Ignoring wrong pointing object 260 65536 (offset 0)\n",
      "Ignoring wrong pointing object 263 65536 (offset 0)\n",
      "Ignoring wrong pointing object 266 65536 (offset 0)\n",
      "Ignoring wrong pointing object 269 65536 (offset 0)\n",
      "Ignoring wrong pointing object 272 65536 (offset 0)\n",
      "Ignoring wrong pointing object 275 65536 (offset 0)\n",
      "Ignoring wrong pointing object 278 65536 (offset 0)\n",
      "Ignoring wrong pointing object 281 65536 (offset 0)\n",
      "Ignoring wrong pointing object 284 65536 (offset 0)\n",
      "Ignoring wrong pointing object 287 65536 (offset 0)\n",
      "Ignoring wrong pointing object 290 65536 (offset 0)\n",
      "Ignoring wrong pointing object 293 65536 (offset 0)\n",
      "Ignoring wrong pointing object 296 65536 (offset 0)\n",
      "Ignoring wrong pointing object 299 65536 (offset 0)\n",
      "Ignoring wrong pointing object 302 65536 (offset 0)\n",
      "Ignoring wrong pointing object 305 65536 (offset 0)\n",
      "Ignoring wrong pointing object 308 65536 (offset 0)\n",
      "Ignoring wrong pointing object 311 65536 (offset 0)\n",
      "Ignoring wrong pointing object 314 65536 (offset 0)\n",
      "Ignoring wrong pointing object 325 65536 (offset 0)\n",
      "Ignoring wrong pointing object 328 65536 (offset 0)\n",
      "Ignoring wrong pointing object 331 65536 (offset 0)\n",
      "Ignoring wrong pointing object 335 65536 (offset 0)\n",
      "Ignoring wrong pointing object 338 65536 (offset 0)\n",
      "Ignoring wrong pointing object 341 65536 (offset 0)\n",
      "Ignoring wrong pointing object 344 65536 (offset 0)\n",
      "Ignoring wrong pointing object 347 65536 (offset 0)\n",
      "Ignoring wrong pointing object 350 65536 (offset 0)\n",
      "Ignoring wrong pointing object 353 65536 (offset 0)\n",
      "Ignoring wrong pointing object 356 65536 (offset 0)\n",
      "Ignoring wrong pointing object 359 65536 (offset 0)\n",
      "Ignoring wrong pointing object 362 65536 (offset 0)\n",
      "Ignoring wrong pointing object 365 65536 (offset 0)\n",
      "Ignoring wrong pointing object 368 65536 (offset 0)\n",
      "Ignoring wrong pointing object 371 65536 (offset 0)\n",
      "Ignoring wrong pointing object 374 65536 (offset 0)\n",
      "Ignoring wrong pointing object 377 65536 (offset 0)\n",
      "Ignoring wrong pointing object 380 65536 (offset 0)\n",
      "Ignoring wrong pointing object 383 65536 (offset 0)\n",
      "Ignoring wrong pointing object 386 65536 (offset 0)\n",
      "Ignoring wrong pointing object 389 65536 (offset 0)\n",
      "Ignoring wrong pointing object 394 65536 (offset 0)\n",
      "Ignoring wrong pointing object 397 65536 (offset 0)\n",
      "Ignoring wrong pointing object 401 65536 (offset 0)\n",
      "Ignoring wrong pointing object 404 65536 (offset 0)\n",
      "Ignoring wrong pointing object 407 65536 (offset 0)\n",
      "Ignoring wrong pointing object 410 65536 (offset 0)\n",
      "Ignoring wrong pointing object 413 65536 (offset 0)\n",
      "Ignoring wrong pointing object 416 65536 (offset 0)\n",
      "Ignoring wrong pointing object 419 65536 (offset 0)\n",
      "Ignoring wrong pointing object 422 65536 (offset 0)\n",
      "Ignoring wrong pointing object 425 65536 (offset 0)\n",
      "Ignoring wrong pointing object 428 65536 (offset 0)\n",
      "Ignoring wrong pointing object 431 65536 (offset 0)\n",
      "Ignoring wrong pointing object 434 65536 (offset 0)\n",
      "Ignoring wrong pointing object 437 65536 (offset 0)\n",
      "Ignoring wrong pointing object 440 65536 (offset 0)\n",
      "Ignoring wrong pointing object 443 65536 (offset 0)\n",
      "Ignoring wrong pointing object 446 65536 (offset 0)\n",
      "Ignoring wrong pointing object 449 65536 (offset 0)\n",
      "Ignoring wrong pointing object 452 65536 (offset 0)\n",
      "Ignoring wrong pointing object 455 65536 (offset 0)\n",
      "Ignoring wrong pointing object 458 65536 (offset 0)\n",
      "Ignoring wrong pointing object 461 65536 (offset 0)\n",
      "Ignoring wrong pointing object 464 65536 (offset 0)\n",
      "Ignoring wrong pointing object 467 65536 (offset 0)\n",
      "Ignoring wrong pointing object 470 65536 (offset 0)\n",
      "Ignoring wrong pointing object 473 65536 (offset 0)\n",
      "Ignoring wrong pointing object 476 65536 (offset 0)\n",
      "Ignoring wrong pointing object 479 65536 (offset 0)\n",
      "Ignoring wrong pointing object 482 65536 (offset 0)\n",
      "Ignoring wrong pointing object 485 65536 (offset 0)\n",
      "Ignoring wrong pointing object 488 65536 (offset 0)\n",
      "Ignoring wrong pointing object 491 65536 (offset 0)\n",
      "Ignoring wrong pointing object 494 65536 (offset 0)\n",
      "Ignoring wrong pointing object 497 65536 (offset 0)\n",
      "Ignoring wrong pointing object 500 65536 (offset 0)\n",
      "Ignoring wrong pointing object 503 65536 (offset 0)\n",
      "Ignoring wrong pointing object 506 65536 (offset 0)\n",
      "Ignoring wrong pointing object 509 65536 (offset 0)\n",
      "Ignoring wrong pointing object 512 65536 (offset 0)\n",
      "Ignoring wrong pointing object 515 65536 (offset 0)\n",
      "Ignoring wrong pointing object 518 65536 (offset 0)\n",
      "Ignoring wrong pointing object 521 65536 (offset 0)\n",
      "Ignoring wrong pointing object 524 65536 (offset 0)\n",
      "Ignoring wrong pointing object 527 65536 (offset 0)\n",
      "Ignoring wrong pointing object 530 65536 (offset 0)\n",
      "Ignoring wrong pointing object 533 65536 (offset 0)\n",
      "Ignoring wrong pointing object 536 65536 (offset 0)\n",
      "Ignoring wrong pointing object 539 65536 (offset 0)\n",
      "Ignoring wrong pointing object 542 65536 (offset 0)\n",
      "Ignoring wrong pointing object 545 65536 (offset 0)\n",
      "Ignoring wrong pointing object 548 65536 (offset 0)\n",
      "Ignoring wrong pointing object 551 65536 (offset 0)\n",
      "Ignoring wrong pointing object 554 65536 (offset 0)\n",
      "Ignoring wrong pointing object 557 65536 (offset 0)\n",
      "Ignoring wrong pointing object 560 65536 (offset 0)\n",
      "Ignoring wrong pointing object 563 65536 (offset 0)\n",
      "Ignoring wrong pointing object 566 65536 (offset 0)\n",
      "Ignoring wrong pointing object 569 65536 (offset 0)\n",
      "Ignoring wrong pointing object 572 65536 (offset 0)\n",
      "Ignoring wrong pointing object 575 65536 (offset 0)\n",
      "Ignoring wrong pointing object 578 65536 (offset 0)\n",
      "Ignoring wrong pointing object 581 65536 (offset 0)\n",
      "Ignoring wrong pointing object 584 65536 (offset 0)\n",
      "Ignoring wrong pointing object 587 65536 (offset 0)\n",
      "Ignoring wrong pointing object 590 65536 (offset 0)\n",
      "Ignoring wrong pointing object 593 65536 (offset 0)\n",
      "Ignoring wrong pointing object 596 65536 (offset 0)\n",
      "Ignoring wrong pointing object 599 65536 (offset 0)\n",
      "Ignoring wrong pointing object 602 65536 (offset 0)\n",
      "Ignoring wrong pointing object 605 65536 (offset 0)\n",
      "Ignoring wrong pointing object 608 65536 (offset 0)\n",
      "Ignoring wrong pointing object 611 65536 (offset 0)\n",
      "Ignoring wrong pointing object 614 65536 (offset 0)\n",
      "Ignoring wrong pointing object 617 65536 (offset 0)\n",
      "Ignoring wrong pointing object 620 65536 (offset 0)\n",
      "Ignoring wrong pointing object 623 65536 (offset 0)\n",
      "Ignoring wrong pointing object 626 65536 (offset 0)\n",
      "Ignoring wrong pointing object 629 65536 (offset 0)\n",
      "Ignoring wrong pointing object 632 65536 (offset 0)\n",
      "Ignoring wrong pointing object 635 65536 (offset 0)\n",
      "Ignoring wrong pointing object 638 65536 (offset 0)\n",
      "Ignoring wrong pointing object 641 65536 (offset 0)\n",
      "Ignoring wrong pointing object 644 65536 (offset 0)\n",
      "Ignoring wrong pointing object 647 65536 (offset 0)\n",
      "Ignoring wrong pointing object 650 65536 (offset 0)\n",
      "Ignoring wrong pointing object 653 65536 (offset 0)\n",
      "Ignoring wrong pointing object 656 65536 (offset 0)\n",
      "Ignoring wrong pointing object 660 65536 (offset 0)\n",
      "Ignoring wrong pointing object 663 65536 (offset 0)\n",
      "Ignoring wrong pointing object 666 65536 (offset 0)\n",
      "Ignoring wrong pointing object 669 65536 (offset 0)\n",
      "Ignoring wrong pointing object 672 65536 (offset 0)\n",
      "Ignoring wrong pointing object 675 65536 (offset 0)\n",
      "Ignoring wrong pointing object 678 65536 (offset 0)\n",
      "Ignoring wrong pointing object 689 65536 (offset 0)\n",
      "Ignoring wrong pointing object 692 65536 (offset 0)\n",
      "Ignoring wrong pointing object 695 65536 (offset 0)\n",
      "Ignoring wrong pointing object 698 65536 (offset 0)\n",
      "Ignoring wrong pointing object 701 65536 (offset 0)\n",
      "Ignoring wrong pointing object 704 65536 (offset 0)\n",
      "Ignoring wrong pointing object 707 65536 (offset 0)\n",
      "Ignoring wrong pointing object 710 65536 (offset 0)\n",
      "Ignoring wrong pointing object 713 65536 (offset 0)\n",
      "Ignoring wrong pointing object 716 65536 (offset 0)\n",
      "Ignoring wrong pointing object 719 65536 (offset 0)\n",
      "Ignoring wrong pointing object 722 65536 (offset 0)\n",
      "Ignoring wrong pointing object 725 65536 (offset 0)\n",
      "Ignoring wrong pointing object 728 65536 (offset 0)\n",
      "Ignoring wrong pointing object 731 65536 (offset 0)\n",
      "Ignoring wrong pointing object 734 65536 (offset 0)\n",
      "Ignoring wrong pointing object 737 65536 (offset 0)\n",
      "Ignoring wrong pointing object 740 65536 (offset 0)\n",
      "Ignoring wrong pointing object 743 65536 (offset 0)\n",
      "Ignoring wrong pointing object 746 65536 (offset 0)\n",
      "Ignoring wrong pointing object 749 65536 (offset 0)\n",
      "Ignoring wrong pointing object 752 65536 (offset 0)\n",
      "Ignoring wrong pointing object 755 65536 (offset 0)\n",
      "Ignoring wrong pointing object 758 65536 (offset 0)\n",
      "Ignoring wrong pointing object 761 65536 (offset 0)\n",
      "Ignoring wrong pointing object 764 65536 (offset 0)\n",
      "Ignoring wrong pointing object 767 65536 (offset 0)\n",
      "Ignoring wrong pointing object 770 65536 (offset 0)\n",
      "Ignoring wrong pointing object 773 65536 (offset 0)\n",
      "Ignoring wrong pointing object 776 65536 (offset 0)\n",
      "Ignoring wrong pointing object 779 65536 (offset 0)\n",
      "Ignoring wrong pointing object 782 65536 (offset 0)\n",
      "Ignoring wrong pointing object 785 65536 (offset 0)\n",
      "Ignoring wrong pointing object 788 65536 (offset 0)\n",
      "Ignoring wrong pointing object 791 65536 (offset 0)\n",
      "Ignoring wrong pointing object 794 65536 (offset 0)\n",
      "Ignoring wrong pointing object 797 65536 (offset 0)\n",
      "Ignoring wrong pointing object 800 65536 (offset 0)\n",
      "Ignoring wrong pointing object 803 65536 (offset 0)\n",
      "Ignoring wrong pointing object 806 65536 (offset 0)\n",
      "Ignoring wrong pointing object 809 65536 (offset 0)\n",
      "Ignoring wrong pointing object 812 65536 (offset 0)\n",
      "Ignoring wrong pointing object 815 65536 (offset 0)\n",
      "Ignoring wrong pointing object 818 65536 (offset 0)\n",
      "Ignoring wrong pointing object 821 65536 (offset 0)\n",
      "Ignoring wrong pointing object 824 65536 (offset 0)\n",
      "Ignoring wrong pointing object 827 65536 (offset 0)\n",
      "Ignoring wrong pointing object 830 65536 (offset 0)\n",
      "Ignoring wrong pointing object 833 65536 (offset 0)\n",
      "Ignoring wrong pointing object 836 65536 (offset 0)\n",
      "Ignoring wrong pointing object 839 65536 (offset 0)\n",
      "Ignoring wrong pointing object 842 65536 (offset 0)\n",
      "Ignoring wrong pointing object 845 65536 (offset 0)\n",
      "Ignoring wrong pointing object 848 65536 (offset 0)\n",
      "Ignoring wrong pointing object 851 65536 (offset 0)\n",
      "Ignoring wrong pointing object 854 65536 (offset 0)\n",
      "Ignoring wrong pointing object 857 65536 (offset 0)\n",
      "Ignoring wrong pointing object 860 65536 (offset 0)\n",
      "Ignoring wrong pointing object 863 65536 (offset 0)\n",
      "Ignoring wrong pointing object 866 65536 (offset 0)\n",
      "Ignoring wrong pointing object 869 65536 (offset 0)\n",
      "Ignoring wrong pointing object 872 65536 (offset 0)\n",
      "Ignoring wrong pointing object 875 65536 (offset 0)\n",
      "Ignoring wrong pointing object 878 65536 (offset 0)\n",
      "Ignoring wrong pointing object 881 65536 (offset 0)\n",
      "Ignoring wrong pointing object 884 65536 (offset 0)\n",
      "Ignoring wrong pointing object 887 65536 (offset 0)\n",
      "Ignoring wrong pointing object 890 65536 (offset 0)\n",
      "Ignoring wrong pointing object 893 65536 (offset 0)\n",
      "Ignoring wrong pointing object 896 65536 (offset 0)\n",
      "Ignoring wrong pointing object 899 65536 (offset 0)\n",
      "Ignoring wrong pointing object 902 65536 (offset 0)\n",
      "Ignoring wrong pointing object 905 65536 (offset 0)\n",
      "Ignoring wrong pointing object 908 65536 (offset 0)\n",
      "Ignoring wrong pointing object 911 65536 (offset 0)\n",
      "Ignoring wrong pointing object 914 65536 (offset 0)\n",
      "Ignoring wrong pointing object 917 65536 (offset 0)\n",
      "Ignoring wrong pointing object 920 65536 (offset 0)\n",
      "Ignoring wrong pointing object 923 65536 (offset 0)\n",
      "Ignoring wrong pointing object 926 65536 (offset 0)\n",
      "Ignoring wrong pointing object 929 65536 (offset 0)\n",
      "Ignoring wrong pointing object 932 65536 (offset 0)\n",
      "Ignoring wrong pointing object 935 65536 (offset 0)\n",
      "Ignoring wrong pointing object 938 65536 (offset 0)\n",
      "Ignoring wrong pointing object 941 65536 (offset 0)\n",
      "Ignoring wrong pointing object 944 65536 (offset 0)\n",
      "Ignoring wrong pointing object 947 65536 (offset 0)\n",
      "Ignoring wrong pointing object 950 65536 (offset 0)\n",
      "Ignoring wrong pointing object 953 65536 (offset 0)\n",
      "Ignoring wrong pointing object 956 65536 (offset 0)\n",
      "Ignoring wrong pointing object 959 65536 (offset 0)\n",
      "Ignoring wrong pointing object 962 65536 (offset 0)\n",
      "Ignoring wrong pointing object 965 65536 (offset 0)\n",
      "Ignoring wrong pointing object 968 65536 (offset 0)\n",
      "Ignoring wrong pointing object 971 65536 (offset 0)\n",
      "Ignoring wrong pointing object 974 65536 (offset 0)\n",
      "Ignoring wrong pointing object 977 65536 (offset 0)\n",
      "Ignoring wrong pointing object 980 65536 (offset 0)\n",
      "Ignoring wrong pointing object 983 65536 (offset 0)\n",
      "Ignoring wrong pointing object 986 65536 (offset 0)\n",
      "Ignoring wrong pointing object 989 65536 (offset 0)\n",
      "Ignoring wrong pointing object 992 65536 (offset 0)\n",
      "Ignoring wrong pointing object 995 65536 (offset 0)\n",
      "Ignoring wrong pointing object 998 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1001 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1004 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1007 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1010 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1014 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1018 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1022 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1025 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1029 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1032 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1035 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1038 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1041 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1044 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1047 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1050 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1053 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1056 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1059 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1062 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1065 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1068 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1071 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1077 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1080 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1083 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1086 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1089 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1092 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1095 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1098 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1101 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1112 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1115 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1118 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1121 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1124 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1127 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1130 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1133 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1136 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1139 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1142 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1145 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1148 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1151 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1154 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1157 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1160 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1163 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1166 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1169 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1172 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1175 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1178 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1181 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1184 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1187 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1193 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1196 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1199 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1202 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1205 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1208 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1211 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1214 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1217 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1220 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1223 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1227 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1230 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1233 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1236 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1239 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1242 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1245 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1248 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1251 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1254 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1257 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1260 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1263 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1266 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1269 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1272 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1275 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1278 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1281 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1284 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1287 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1290 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1293 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1296 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1299 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1302 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1305 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1308 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1311 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1314 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1317 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1320 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1323 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1326 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1329 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1332 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1335 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1338 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1341 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1344 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1347 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1350 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1353 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1356 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1359 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1362 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1365 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1368 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1371 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1374 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1377 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1380 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1383 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1386 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1389 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1392 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1395 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1398 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1401 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1404 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1407 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1410 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1413 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1416 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1419 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1422 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1425 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1428 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1431 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1434 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1437 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1440 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1443 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1446 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1449 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1452 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1455 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1458 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1461 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1464 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1467 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1470 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1473 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1476 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1479 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1482 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1485 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1488 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1491 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1494 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1497 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1500 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1503 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1506 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1509 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1512 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1515 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1518 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1521 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1524 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1527 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1530 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1533 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1536 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1539 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1542 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1545 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1548 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1551 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1554 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1557 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1560 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1563 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1566 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1569 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1572 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1575 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1578 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1581 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1584 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1587 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1590 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1593 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1596 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1599 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1602 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1605 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1613 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1617 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1620 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1623 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1626 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1629 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1632 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1635 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1638 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1641 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1644 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1647 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1650 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1653 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1656 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1660 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1663 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1666 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1669 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1672 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1675 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1678 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1681 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1684 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1687 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1690 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1693 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1696 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1699 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1702 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1705 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1708 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1711 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1714 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1717 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1720 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1723 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1726 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1732 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1735 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1738 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1741 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1744 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1747 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1750 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1753 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1756 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1759 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1762 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1765 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1768 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1771 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1774 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1777 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1780 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1783 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1786 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1789 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1792 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1795 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1798 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1801 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1804 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1807 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1810 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1813 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1816 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1819 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1822 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1825 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1828 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1831 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1834 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1837 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1840 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1843 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1846 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1849 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1852 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1855 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1858 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1861 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1864 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1870 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1876 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1879 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1882 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1888 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1892 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1895 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1898 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1904 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1911 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1923 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1933 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1940 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1950 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1959 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1969 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1977 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1980 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1988 65536 (offset 0)\n",
      "Ignoring wrong pointing object 1996 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2002 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2005 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2008 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2011 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2014 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2019 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2022 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2025 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2028 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2031 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2034 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2037 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2040 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2043 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2046 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2049 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2052 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2055 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2058 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2061 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2064 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2067 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2070 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2073 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2076 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2079 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2082 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2085 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2088 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2091 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2094 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2097 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2100 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2103 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2106 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2109 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2112 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2115 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2118 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2121 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2124 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2127 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2130 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2133 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2136 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2139 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2142 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2145 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2148 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2151 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2154 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2157 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2160 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2163 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2166 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2169 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2172 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2175 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2178 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2181 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2184 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2187 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2193 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2196 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2199 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2202 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2205 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2208 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2211 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2214 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2217 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2220 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2223 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2226 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2229 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2232 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2235 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2238 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2241 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2244 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2247 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2250 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2253 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2256 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2259 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2262 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2265 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2268 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2271 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2274 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2277 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2280 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2283 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2286 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2289 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2292 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2295 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2298 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2301 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2304 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2307 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2310 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2313 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2316 65536 (offset 0)\n",
      "Ignoring wrong pointing object 2319 65536 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   5%|▌         | 558/10445 [04:43<4:26:33,  1.62s/it]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 36 65536 (offset 0)\n",
      "Ignoring wrong pointing object 49 65536 (offset 0)\n",
      "Ignoring wrong pointing object 60 65536 (offset 0)\n",
      "Ignoring wrong pointing object 63 65536 (offset 0)\n",
      "Ignoring wrong pointing object 66 65536 (offset 0)\n",
      "Ignoring wrong pointing object 69 65536 (offset 0)\n",
      "Ignoring wrong pointing object 72 65536 (offset 0)\n",
      "Ignoring wrong pointing object 75 65536 (offset 0)\n",
      "Ignoring wrong pointing object 78 65536 (offset 0)\n",
      "Ignoring wrong pointing object 81 65536 (offset 0)\n",
      "Ignoring wrong pointing object 84 65536 (offset 0)\n",
      "Ignoring wrong pointing object 87 65536 (offset 0)\n",
      "Ignoring wrong pointing object 90 65536 (offset 0)\n",
      "Ignoring wrong pointing object 93 65536 (offset 0)\n",
      "Ignoring wrong pointing object 96 65536 (offset 0)\n",
      "Ignoring wrong pointing object 99 65536 (offset 0)\n",
      "Ignoring wrong pointing object 102 65536 (offset 0)\n",
      "Ignoring wrong pointing object 113 65536 (offset 0)\n",
      "Ignoring wrong pointing object 116 65536 (offset 0)\n",
      "Ignoring wrong pointing object 119 65536 (offset 0)\n",
      "Ignoring wrong pointing object 122 65536 (offset 0)\n",
      "Ignoring wrong pointing object 125 65536 (offset 0)\n",
      "Ignoring wrong pointing object 128 65536 (offset 0)\n",
      "Ignoring wrong pointing object 133 65536 (offset 0)\n",
      "Ignoring wrong pointing object 136 65536 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   6%|▋         | 676/10445 [05:09<40:10,  4.05it/s]  Ignoring wrong pointing object 16 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   7%|▋         | 768/10445 [06:14<36:41,  4.39it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error loading cancer-facts-and-figures-2021.pdf: cryptography>=3.1 is required for AES algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   8%|▊         | 815/10445 [06:28<27:15,  5.89it/s]  parsing for Object Streams\n",
      "parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   8%|▊         | 817/10445 [06:28<23:18,  6.88it/s]parsing for Object Streams\n",
      "parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   8%|▊         | 819/10445 [06:28<20:49,  7.70it/s]parsing for Object Streams\n",
      "parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   8%|▊         | 821/10445 [06:28<23:47,  6.74it/s]parsing for Object Streams\n",
      "parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   8%|▊         | 823/10445 [06:29<20:28,  7.83it/s]parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   9%|▉         | 943/10445 [06:58<1:29:07,  1.78it/s]Ignoring wrong pointing object 18 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:   9%|▉         | 945/10445 [06:59<1:12:54,  2.17it/s]Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  10%|▉         | 1010/10445 [07:09<15:45,  9.98it/s] parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  11%|█         | 1175/10445 [08:07<2:02:50,  1.26it/s] parsing for Object Streams\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  12%|█▏        | 1240/10445 [08:27<1:04:39,  2.37it/s]Ignoring wrong pointing object 0 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  12%|█▏        | 1279/10445 [09:09<11:13:33,  4.41s/it]Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  19%|█▉        | 1960/10445 [11:46<1:33:36,  1.51it/s] Unexpected escaped string: W\n",
      "Unexpected escaped string: U\n",
      "Unexpected escaped string: S\n",
      "Unexpected escaped string: A\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  19%|█▉        | 1973/10445 [11:52<34:27,  4.10it/s]  Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion:  19%|█▉        | 1980/10445 [11:55<34:10,  4.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error loading NIH-CADR-Implementation-Guidebook.pdf: cryptography>=3.1 is required for AES algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄 Loading files from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion: 100%|██████████| 10445/10445 [18:12<00:00,  9.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 52733 pages from 10445 files in 'c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\general_web_ingestion'.\n",
      "🧩 Created 541409 chunks from 52733 document pages.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 2 — Load PDFs and TXT Files, Split into Text Chunks\n",
    "# =========================================================\n",
    "\n",
    "# --- Imports ---\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Optional: Silence PDFMiner warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pdfminer\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Load PDFs and TXT files\n",
    "# --------------------------------------------------------\n",
    "def load_docs_from_folder(folder: Path):\n",
    "    \"\"\"\n",
    "    Load all PDF and TXT files from a folder into LangChain Document objects.\n",
    "    Skips unreadable or corrupted files gracefully.\n",
    "    \"\"\"\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"❌ Folder not found: {folder}\")\n",
    "\n",
    "    pdf_files = sorted(folder.glob(\"*.pdf\"))\n",
    "    txt_files = sorted(folder.glob(\"*.txt\"))\n",
    "    all_files = pdf_files + txt_files\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"⚠️ No PDF or TXT files found in {folder}\")\n",
    "\n",
    "    docs = []\n",
    "    for fpath in tqdm(all_files, desc=f\"📄 Loading files from {folder}\"):\n",
    "        try:\n",
    "            if fpath.suffix.lower() == \".pdf\":\n",
    "                loader = PyPDFLoader(str(fpath))\n",
    "            elif fpath.suffix.lower() == \".txt\":\n",
    "                loader = TextLoader(str(fpath), encoding=\"utf-8\")\n",
    "            else:\n",
    "                print(f\"⏭️ Skipped unsupported file: {fpath.name}\")\n",
    "                continue\n",
    "\n",
    "            file_docs = loader.load()\n",
    "            docs.extend(file_docs)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {fpath.name}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Loaded {len(docs)} pages from {len(all_files)} files in '{folder}'.\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Split documents into text chunks\n",
    "# --------------------------------------------------------\n",
    "def split_into_chunks(docs, chunk_size=800, chunk_overlap=120):\n",
    "    \"\"\"\n",
    "    Split LangChain Document objects into overlapping chunks\n",
    "    for embeddings and retrieval-augmented generation (RAG).\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(f\"🧩 Created {len(chunks)} chunks from {len(docs)} document pages.\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Example Run\n",
    "\n",
    "\n",
    "# Load and split\n",
    "raw_docs = load_docs_from_folder(DATA_PDFS)\n",
    "chunks = split_into_chunks(raw_docs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0f00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahid\\AppData\\Local\\Temp\\ipykernel_47028\\2321972389.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧱 Building new FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔢 Embedding text chunks: 100%|██████████| 541409/541409 [00:00<00:00, 3355087.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved new FAISS index to c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss_index\n",
      "⏱️ Build completed in 69.23 minutes (4153.8 seconds)\n",
      "✅ Retriever ready (top_k=6)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 3 — Build or Load FAISS Index\n",
    "# ============================================\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import time\n",
    "\n",
    "# --- Initialize embedding model ---\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "def build_or_load_faiss_index(index_dir=INDEX_DIR, chunks=None):\n",
    "    \"\"\"\n",
    "    Builds a new FAISS index from text chunks if none exists,\n",
    "    otherwise loads the saved one from disk.\n",
    "    \"\"\"\n",
    "    faiss_path = index_dir / \"index.faiss\"\n",
    "    pkl_path   = index_dir / \"index.pkl\"\n",
    "\n",
    "    # --- If index exists, load it ---\n",
    "    if faiss_path.exists() and pkl_path.exists():\n",
    "        print(\"📦 Existing FAISS index found. Loading from disk...\")\n",
    "        vectorstore = FAISS.load_local(\n",
    "            str(index_dir),\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\"✅ FAISS index loaded successfully.\")\n",
    "        return vectorstore\n",
    "\n",
    "    # --- Otherwise, build new index ---\n",
    "    if chunks is None or len(chunks) == 0:\n",
    "        raise RuntimeError(\"❌ No chunks provided. Please run Step 2 first to load and split PDFs.\")\n",
    "\n",
    "    print(\"🧱 Building new FAISS index...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        tqdm(chunks, desc=\"🔢 Embedding text chunks\"),\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    # --- Save the index ---\n",
    "    vectorstore.save_local(str(index_dir))\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    print(f\"💾 Saved new FAISS index to {index_dir}\")\n",
    "    print(f\"⏱️ Build completed in {duration/60:.2f} minutes ({duration:.1f} seconds)\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# --- Execute step ---\n",
    "vectorstore = build_or_load_faiss_index(INDEX_DIR, chunks)\n",
    "retriever   = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "print(f\"✅ Retriever ready (top_k={TOP_K})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d9b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Excel loaded successfully: 26 rows\n",
      "✅ DMP Markdown template loaded.\n",
      "🔗 RAG chain initialized with model: llama3.3\n",
      "✅ RAG chain ready for generation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🧩 STEP 4 — Load Excel, Template, and Build RAG Chain (Fixed)\n",
    "# ============================================\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load Excel file ---\n",
    "if not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"❌ Excel file not found: {EXCEL_PATH}\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(f\"✅ Excel loaded successfully: {len(df)} rows\")\n",
    "\n",
    "# --- Load Markdown Template ---\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"❌ Template file not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(\"✅ DMP Markdown template loaded.\")\n",
    "\n",
    "\n",
    "# --- Build RAG chain ---\n",
    "def build_rag_chain(retriever, llm_model=LLM_MODEL):\n",
    "    \"\"\"\n",
    "    Build a flexible RAG pipeline that retrieves context\n",
    "    and generates a context-grounded NIH DMP section.\n",
    "    \"\"\"\n",
    "    llm = Ollama(model=llm_model)\n",
    "\n",
    "    prompt_template = \"\"\"You are an expert biomedical data steward and grant writer.\n",
    "Create a high-quality NIH Data Management and Sharing Plan (DMSP)\n",
    "based on the retrieved NIH context and the user's query.\n",
    "\n",
    "----\n",
    "Context from NIH Repository:\n",
    "{context}\n",
    "\n",
    "----\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Use the context above and follow the NIH template structure. Write fluently and cohesively.\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    def format_docs(docs):\n",
    "        \"\"\"Format retrieved documents into clean text.\"\"\"\n",
    "        if not docs:\n",
    "            return \"\"\n",
    "        formatted = []\n",
    "        for d in docs:\n",
    "            page = d.metadata.get(\"page\", \"\")\n",
    "            title = d.metadata.get(\"source\", \"\")\n",
    "            formatted.append(f\"[Page {page}] {title}\\n{d.page_content.strip()}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    print(f\"🔗 RAG chain initialized with model: {llm_model}\")\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "# --- Initialize the RAG chain ---\n",
    "rag_chain = build_rag_chain(retriever)\n",
    "print(\"✅ RAG chain ready for generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd1758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded input Excel — 26 rows\n",
      "✅ Loaded NIH DMP Markdown template from: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧩 Generating DMP for: Clinical and MRI data from human research participants\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:   4%|▍         | 1/26 [01:42<42:35, 102.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical and MRI data from human research participants.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical and MRI data from human research participants.docx\n",
      "\n",
      "🧩 Generating DMP for: Genomic data from human research participants\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:   8%|▊         | 2/26 [03:11<37:45, 94.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Genomic data from human research participants.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Genomic data from human research participants.docx\n",
      "\n",
      "🧩 Generating DMP for: Genomic data from a non-human source\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  12%|█▏        | 3/26 [04:27<33:06, 86.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Genomic data from a non-human source.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Genomic data from a non-human source.docx\n",
      "\n",
      "🧩 Generating DMP for: Secondary data analysis\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  15%|█▌        | 4/26 [05:54<31:42, 86.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary data analysis.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary data analysis.docx\n",
      "\n",
      "🧩 Generating DMP for: Human clinical and genomics data\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  19%|█▉        | 5/26 [07:25<30:50, 88.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human clinical and genomics data.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human clinical and genomics data.docx\n",
      "\n",
      "🧩 Generating DMP for: Gene expression analysis data from non-human model organism (zebrafish)\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  23%|██▎       | 6/26 [08:50<29:03, 87.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Gene expression analysis data from non-human model organism (zebrafish).md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Gene expression analysis data from non-human model organism (zebrafish).docx\n",
      "\n",
      "🧩 Generating DMP for: Human survey data\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  27%|██▋       | 7/26 [10:10<26:46, 84.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human survey data.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human survey data.docx\n",
      "\n",
      "🧩 Generating DMP for: Clinical Data from Human Research Participants\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  31%|███       | 8/26 [11:36<25:34, 85.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical Data from Human Research Participants.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical Data from Human Research Participants.docx\n",
      "\n",
      "🧩 Generating DMP for: Human genomic data\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  35%|███▍      | 9/26 [13:11<25:01, 88.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human genomic data.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human genomic data.docx\n",
      "\n",
      "🧩 Generating DMP for: Technology development\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  38%|███▊      | 10/26 [14:33<23:01, 86.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Technology development.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Technology development.docx\n",
      "\n",
      "🧩 Generating DMP for: Basic Research from a Non-Human Source Example\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  42%|████▏     | 11/26 [16:01<21:41, 86.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Basic Research from a Non-Human Source Example.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Basic Research from a Non-Human Source Example.docx\n",
      "\n",
      "🧩 Generating DMP for: Secondary Data Analysis Example\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  46%|████▌     | 12/26 [17:19<19:38, 84.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary Data Analysis Example.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary Data Analysis Example.docx\n",
      "\n",
      "🧩 Generating DMP for: Survey and Interview Example\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  50%|█████     | 13/26 [18:48<18:31, 85.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey and Interview Example.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey and Interview Example.docx\n",
      "\n",
      "🧩 Generating DMP for: Human Clinical Trial Data\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  54%|█████▍    | 14/26 [20:14<17:06, 85.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human Clinical Trial Data.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human Clinical Trial Data.docx\n",
      "\n",
      "🧩 Generating DMP for: Clinical data from human research participants-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  58%|█████▊    | 15/26 [21:35<15:28, 84.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical data from human research participants-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical data from human research participants-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Survey, interview, and biological data (tiered access)\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  62%|██████▏   | 16/26 [22:43<13:13, 79.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey, interview, and biological data (tiered access).md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey, interview, and biological data (tiered access).docx\n",
      "\n",
      "🧩 Generating DMP for: Non-human data (primates)\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  65%|██████▌   | 17/26 [23:44<11:05, 73.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Non-human data (primates).md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Non-human data (primates).docx\n",
      "\n",
      "🧩 Generating DMP for: Secondary data analysis-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  69%|██████▉   | 18/26 [25:06<10:11, 76.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary data analysis-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary data analysis-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Survey and interview data-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  73%|███████▎  | 19/26 [26:22<08:53, 76.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey and interview data-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey and interview data-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Human clinical and genomic data-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  77%|███████▋  | 20/26 [27:54<08:04, 80.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human clinical and genomic data-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human clinical and genomic data-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Non-human data (rodents)-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  81%|████████  | 21/26 [29:29<07:06, 85.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Non-human data (rodents)-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Non-human data (rodents)-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Clinical data (human biospecimens)\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  85%|████████▍ | 22/26 [30:48<05:33, 83.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical data (human biospecimens).md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical data (human biospecimens).docx\n",
      "\n",
      "🧩 Generating DMP for: Drug discovery including intellectual property\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  88%|████████▊ | 23/26 [32:06<04:05, 81.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Drug discovery including intellectual property.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Drug discovery including intellectual property.docx\n",
      "\n",
      "🧩 Generating DMP for: HeLa Cell Whole Genome Sequence (DNA or RNA)\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  92%|█████████▏| 24/26 [33:33<02:46, 83.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\HeLa Cell Whole Genome Sequence (DNA or RNA).md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\HeLa Cell Whole Genome Sequence (DNA or RNA).docx\n",
      "\n",
      "🧩 Generating DMP for: Secondary Data Analysis on Data from Human Subjects-NIA\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs:  96%|█████████▌| 25/26 [34:59<01:24, 84.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary Data Analysis on Data from Human Subjects-NIA.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary Data Analysis on Data from Human Subjects-NIA.docx\n",
      "\n",
      "🧩 Generating DMP for: Analysis of social media posts\n",
      "🔎 Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Generating NIH DMPs: 100%|██████████| 26/26 [36:18<00:00, 83.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Analysis of social media posts.md\n",
      "📄 Converted: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Analysis of social media posts.docx\n",
      "\n",
      "✅ All NIH DMPs generated successfully — titles preserved exactly as in Excel!\n",
      "📊 CSV log saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\rag_generated_dmp_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🧩 STEP 5 — RAG-Based DMP Generation Using Titles\n",
    "# ============================================\n",
    "import re, pandas as pd, pypandoc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Paths ----------\n",
    "EXCEL_PATH = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "OUTPUT_LOG = ROOT_DIR / \"data\" / \"outputs\" / \"rag_generated_dmp_log.csv\"\n",
    "OUTPUT_MD.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DOCX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load Excel ----------\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(f\"✅ Loaded input Excel — {len(df)} rows\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# ---------- Verify template ----------\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"❌ Template not found: {TEMPLATE_MD}\")\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(f\"✅ Loaded NIH DMP Markdown template from: {TEMPLATE_MD}\")\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"Replace illegal filename characters but preserve readable title.\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name.strip())\n",
    "\n",
    "def create_folder(folderpath: Path):\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath: Path, filename: str, response: str):\n",
    "    create_folder(folderpath)\n",
    "    filepath = folderpath / filename\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)\n",
    "    print(f\"💾 Saved: {filepath}\")\n",
    "\n",
    "def md_to_docx(md_filepath: Path, docx_folder: Path, docx_filename: str):\n",
    "    create_folder(docx_folder)\n",
    "    docx_path = docx_folder / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(docx_path))\n",
    "    print(f\"📄 Converted: {docx_path}\")\n",
    "\n",
    "# ---------- Main Generation ----------\n",
    "records = []\n",
    "TOP_K = 6  # retrieved context chunks\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"🧠 Generating NIH DMPs\"):\n",
    "    title = str(row[\"title\"]).strip()\n",
    "    print(f\"\\n🧩 Generating DMP for: {title}\")\n",
    "\n",
    "    # 1️⃣ Build query from Excel elements\n",
    "    element_texts = []\n",
    "    for col in [c for c in df.columns if c.startswith(\"element\")]:\n",
    "        val = str(row[col]).strip()\n",
    "        if val:\n",
    "            element_texts.append(f\"{col.upper()}: {val}\")\n",
    "    query_data = \"\\n\".join(element_texts)\n",
    "\n",
    "    query = (\n",
    "        f\"You are an expert biomedical data steward and grant writer. \"\n",
    "        f\"Create a complete NIH Data Management and Sharing Plan (DMSP) for the project titled '{title}'. \"\n",
    "        f\"Use retrieved context from the NIH corpus to fill in all template sections accurately.\\n\\n\"\n",
    "        f\"Here is background information from the proposal:\\n{query_data}\\n\"\n",
    "    )\n",
    "\n",
    "    # 2️⃣ Retrieve context from FAISS\n",
    "    try:\n",
    "        retrieved_docs = retriever.get_relevant_documents(query)\n",
    "        context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs[:TOP_K])\n",
    "        print(f\"🔎 Retrieved {len(retrieved_docs)} context chunks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Retrieval failed for {title}: {e}\")\n",
    "        context_text = \"\"\n",
    "\n",
    "    # 3️⃣ Combine context, query, and template\n",
    "    full_prompt = f\"\"\"\n",
    "You are an expert biomedical data steward and grant writer.\n",
    "Use the retrieved NIH context and the provided template to generate a complete Data Management and Sharing Plan.\n",
    "\n",
    "----\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "----\n",
    "Project Query:\n",
    "{query}\n",
    "\n",
    "Use the following NIH DMSP Markdown template. Do not alter section titles:\n",
    "{dmp_template_text}\n",
    "\"\"\"\n",
    "\n",
    "    # 4️⃣ Run through RAG model\n",
    "    try:\n",
    "        response = rag_chain.invoke(full_prompt)\n",
    "\n",
    "        # 5️⃣ Save using SAME TITLE as in Excel\n",
    "        safe_title = sanitize_filename(title)\n",
    "        md_filename = f\"{safe_title}.md\"\n",
    "        docx_filename = f\"{safe_title}.docx\"\n",
    "        md_path = OUTPUT_MD / md_filename\n",
    "\n",
    "        save_md(OUTPUT_MD, md_filename, response)\n",
    "        md_to_docx(md_path, OUTPUT_DOCX, docx_filename)\n",
    "\n",
    "        # 6️⃣ Log summary\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": response[:1000],\n",
    "            \"Error\": \"\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating DMP for {title}: {e}\")\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": \"\",\n",
    "            \"Error\": str(e)\n",
    "        })\n",
    "\n",
    "# ---------- Save Log ----------\n",
    "pd.DataFrame(records).to_csv(OUTPUT_LOG, index=False, encoding=\"utf-8\")\n",
    "print(\"\\n✅ All NIH DMPs generated successfully — titles preserved exactly as in Excel!\")\n",
    "print(f\"📊 CSV log saved to: {OUTPUT_LOG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db58c3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📗 Gold PDF folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\gold_dmps\n",
      "📘 Generated Markdown folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "🚀 Loading models...\n",
      "✅ Models ready.\n",
      "📊 Found 26 generated DMPs and 26 gold PDFs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:   4%|▍         | 1/26 [00:00<00:08,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Analysis of social media posts.md ↔ 26-Analysis of social media posts-NCI.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:   8%|▊         | 2/26 [00:00<00:08,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Basic Research from a Non-Human Source Example.md ↔ 11-Basic Research from a Non-Human Source Example-NIDDK.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  12%|█▏        | 3/26 [00:01<00:09,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Clinical and MRI data from human research participants.md ↔ 1-Clinical andor MRI data from human research participants-NIMH.pdf (score=0.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  15%|█▌        | 4/26 [00:01<00:09,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Clinical data (human biospecimens).md ↔ 22-Clinical data (human biospecimens)-NIA.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  19%|█▉        | 5/26 [00:01<00:08,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Clinical data from human research participants-NIA.md ↔ 15-Clinical data from human research participants-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  23%|██▎       | 6/26 [00:02<00:07,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Clinical Data from Human Research Participants.md ↔ 15-Clinical data from human research participants-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  27%|██▋       | 7/26 [00:02<00:07,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Drug discovery including intellectual property.md ↔ 23-Drug discovery including intellectual property-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  31%|███       | 8/26 [00:03<00:06,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Gene expression analysis data from non-human model organism (zebrafish).md ↔ 8-Gene expression analysis data from non-human model organism (zebrafish)-NICHD.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  35%|███▍      | 9/26 [00:03<00:06,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Genomic data from a non-human source.md ↔ 3-Genomic data from a non-human source-NIMH.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  38%|███▊      | 10/26 [00:04<00:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Genomic data from human research participants.md ↔ 2-Genomic data from human research participants-NIMH.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  42%|████▏     | 11/26 [00:04<00:06,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched HeLa Cell Whole Genome Sequence (DNA or RNA).md ↔ 24-HeLa Cell Whole Genome Sequence (DNA or RNA)-OD, NHGRI.pdf (score=0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  46%|████▌     | 12/26 [00:04<00:06,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Human clinical and genomic data-NIA.md ↔ 20-Human clinical and genomic data-NIA.pdf (score=0.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  50%|█████     | 13/26 [00:05<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Human clinical and genomics data.md ↔ 7-Human clinical and genomics data-NICHD.pdf (score=0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  54%|█████▍    | 14/26 [00:05<00:05,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Human Clinical Trial Data.md ↔ 14-Human Clinical Trial Data-NICHD.pdf (score=0.85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  58%|█████▊    | 15/26 [00:06<00:05,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Human genomic data.md ↔ 5-Human genomic data-NHGRI.pdf (score=0.82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  62%|██████▏   | 16/26 [00:06<00:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Human survey data.md ↔ 9-Human survey data-NICHD.pdf (score=0.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  65%|██████▌   | 17/26 [00:07<00:03,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Non-human data (primates).md ↔ 17-Non-human data (primates)-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  69%|██████▉   | 18/26 [00:07<00:03,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Non-human data (rodents)-NIA.md ↔ 21-Non-human data (rodents)-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  73%|███████▎  | 19/26 [00:07<00:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Secondary Data Analysis Example.md ↔ 12-Secondary Data Analysis Example-NIDDK.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  77%|███████▋  | 20/26 [00:08<00:02,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Secondary Data Analysis on Data from Human Subjects-NIA.md ↔ 25-Secondary Data Analysis on Data from Human Subjects-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  81%|████████  | 21/26 [00:08<00:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Secondary data analysis-NIA.md ↔ 18-Secondary data analysis-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  85%|████████▍ | 22/26 [00:08<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Secondary data analysis.md ↔ 18-Secondary data analysis-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  88%|████████▊ | 23/26 [00:09<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Survey and interview data-NIA.md ↔ 19-Survey and interview data-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  92%|█████████▏| 24/26 [00:09<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Survey and Interview Example.md ↔ 13-Survey and Interview Example-NHGRI.pdf (score=0.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs:  96%|█████████▌| 25/26 [00:10<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Survey, interview, and biological data (tiered access).md ↔ 16-Survey, interview, and biological data (tiered access)-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔎 Matching & Comparing DMPs: 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matched Technology development.md ↔ 6-Technology development-NHGRI.pdf (score=0.85)\n",
      "\n",
      "✅ Markdown–PDF (fuzzy) similarity results saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\full_dmp_pdf_comparison_fuzzy.csv\n",
      "🧾 Total matched DMP pairs: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🧩 STEP 7 — Full DMP Comparison: Markdown (Generated) vs PDF (Gold, Fuzzy Matching)\n",
    "# ============================================\n",
    "import os, re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 🗂️ Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ✅ change if needed\n",
    "\n",
    "# --- Paths ---\n",
    "GOLD_DIR      = ROOT_DIR / \"data\" /\"inputs\"/ \"gold_dmps\"      # PDF gold-standard DMPs\n",
    "GENERATED_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"      # Generated DMPs\n",
    "EVAL_DIR      = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"📗 Gold PDF folder: {GOLD_DIR}\")\n",
    "print(f\"📘 Generated Markdown folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"🚀 Loading models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"✅ Models ready.\")\n",
    "\n",
    "# --- Helper functions ---\n",
    "def normalize_name(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove markdown or formatting artifacts.\"\"\"\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"#+\\s*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*|\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract readable text from PDF using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading {pdf_path.name}: {e}\")\n",
    "    return clean_text(text)\n",
    "\n",
    "def chunk_text(text, size=300):\n",
    "    \"\"\"Split long text into 300-word chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "def compare_chunked(gold_text, gen_text, model):\n",
    "    \"\"\"Chunked SBERT + ROUGE similarity between two long texts.\"\"\"\n",
    "    gold_chunks = chunk_text(gold_text)\n",
    "    gen_chunks = chunk_text(gen_text)\n",
    "\n",
    "    sbert_scores, rouge_scores = [], []\n",
    "    for g in gold_chunks:\n",
    "        emb_g = model.encode(g, convert_to_tensor=True)\n",
    "        chunk_sims = []\n",
    "        for gen in gen_chunks:\n",
    "            emb_gen = model.encode(gen, convert_to_tensor=True)\n",
    "            chunk_sims.append(util.cos_sim(emb_g, emb_gen).item())\n",
    "        sbert_scores.append(max(chunk_sims))  # best match per gold chunk\n",
    "\n",
    "        rouge_chunk_scores = [rouge.score(g, gen)[\"rougeL\"].recall for gen in gen_chunks]\n",
    "        rouge_scores.append(max(rouge_chunk_scores))\n",
    "\n",
    "    return np.mean(sbert_scores), np.mean(rouge_scores)\n",
    "\n",
    "def best_fuzzy_match(target, gold_names, threshold=0.6):\n",
    "    \"\"\"Find best matching name among gold files using fuzzy ratio.\"\"\"\n",
    "    best_match, best_score = None, 0\n",
    "    for g in gold_names:\n",
    "        score = SequenceMatcher(None, target, g).ratio()\n",
    "        if score > best_score:\n",
    "            best_match, best_score = g, score\n",
    "    return (best_match, best_score) if best_score >= threshold else (None, best_score)\n",
    "\n",
    "# --- Collect gold PDFs and generated MDs ---\n",
    "gold_files = {normalize_name(f.stem): f for f in GOLD_DIR.glob(\"*.pdf\")}\n",
    "gen_files  = {normalize_name(f.stem): f for f in GENERATED_DIR.glob(\"*.md\")}\n",
    "print(f\"📊 Found {len(gen_files)} generated DMPs and {len(gold_files)} gold PDFs.\")\n",
    "\n",
    "# --- Compare all matching files ---\n",
    "results = []\n",
    "for name, gen_path in tqdm(gen_files.items(), desc=\"🔎 Matching & Comparing DMPs\"):\n",
    "    best_match, score = best_fuzzy_match(name, list(gold_files.keys()))\n",
    "    if not best_match:\n",
    "        print(f\"⚠️ No gold match for: {gen_path.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_path = gold_files[best_match]\n",
    "    gold_text = extract_text_from_pdf(gold_path)\n",
    "    gen_text  = clean_text(gen_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    if not gold_text.strip() or not gen_text.strip():\n",
    "        print(f\"⚠️ Skipping empty file: {name}\")\n",
    "        continue\n",
    "\n",
    "    sbert_sim, rouge_l = compare_chunked(gold_text, gen_text, sbert)\n",
    "    results.append({\n",
    "        \"Generated_File\": gen_path.name,\n",
    "        \"Matched_Gold_PDF\": gold_path.name,\n",
    "        \"Match_Score\": round(score, 3),\n",
    "        \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "        \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "    })\n",
    "    print(f\"✅ Matched {gen_path.name} ↔ {gold_path.name} (score={score:.2f})\")\n",
    "\n",
    "# --- Save results ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "df_results.to_csv(out_path, index=False)\n",
    "print(f\"\\n✅ Markdown–PDF (fuzzy) similarity results saved to: {out_path}\")\n",
    "print(f\"🧾 Total matched DMP pairs: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c307ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 ROOT_DIR set to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "📗 Gold Excel: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "📘 Generated MD folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "✅ Loaded 26 gold projects.\n",
      "🚀 Loading evaluation models...\n",
      "✅ Models ready.\n",
      "🔍 Found 26 generated Markdown files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📊 Comparing element-level: 100%|██████████| 26/26 [00:54<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Element-level similarity saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\element_similarity_exact_titles.csv\n",
      "🧾 Total element–section best matches: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🧩 STEP 7 — Element-Level Comparison with NIH Gold Standard (Exact Title Match)\n",
    "# ============================================\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --- Paths ---\n",
    "# --- Define ROOT_DIR dynamically (project root) ---\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 🗂️ Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ✅ change if needed\n",
    "\n",
    "print(f\"📂 ROOT_DIR set to: {ROOT_DIR}\")\n",
    "GOLD_PATH      = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "GENERATED_DIR  = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "EVAL_DIR       = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"📗 Gold Excel: {GOLD_PATH}\")\n",
    "print(f\"📘 Generated MD folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Load gold reference (Excel) ---\n",
    "df_gold = pd.read_excel(GOLD_PATH)\n",
    "df_gold.columns = df_gold.columns.str.strip().str.lower()\n",
    "df_gold = df_gold.fillna(\"\").astype(str)\n",
    "\n",
    "def normalize_title(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "df_gold[\"title_norm\"] = df_gold[\"title\"].apply(normalize_title)\n",
    "\n",
    "gold_elements = [\n",
    "    \"element_1a\",\"element_1b\",\"element_1c\",\n",
    "    \"element_2\",\"element_3\",\n",
    "    \"element_4a\",\"element_4b\",\"element_4c\",\n",
    "    \"element_5a\",\"element_5b\",\"element_5c\",\n",
    "    \"element_6\"\n",
    "]\n",
    "print(f\"✅ Loaded {len(df_gold)} gold projects.\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"🚀 Loading evaluation models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"✅ Models ready.\")\n",
    "\n",
    "# --- Markdown parsing helpers ---\n",
    "def is_title(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    # Accept markdown headers (#, ##, ...) OR numbered bold section titles like \"1. **Data Types**\"\n",
    "    return s.startswith(\"#\") or bool(re.match(r\"^\\s*\\d*\\.?\\s*\\*\\*.*\\*\\*\\s*$\", s))\n",
    "\n",
    "def extract_sections(md_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract {Section Title, Generated Content} pairs from a Markdown file.\n",
    "    Also strips any <think>...</think> blocks if present.\n",
    "    \"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\")\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    entries, current_title, buf = [], None, []\n",
    "\n",
    "    for ln in lines:\n",
    "        if is_title(ln):\n",
    "            if current_title and any(x.strip() for x in buf):\n",
    "                entries.append({\n",
    "                    \"Section Title\": current_title.strip(),\n",
    "                    \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "                })\n",
    "            current_title, buf = ln, []\n",
    "        else:\n",
    "            buf.append(ln)\n",
    "\n",
    "    if current_title and any(x.strip() for x in buf):\n",
    "        entries.append({\n",
    "            \"Section Title\": current_title.strip(),\n",
    "            \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# --- Compare (exact title match) ---\n",
    "results = []\n",
    "md_files = sorted(GENERATED_DIR.glob(\"*.md\"))\n",
    "print(f\"🔍 Found {len(md_files)} generated Markdown files.\")\n",
    "\n",
    "for md_file in tqdm(md_files, desc=\"📊 Comparing element-level\"):\n",
    "    # Your MD files are saved with the SAME title (sanitized) — reverse-sanitize to match Excel\n",
    "    # We’ll normalize both sides and do exact equality on normalized strings\n",
    "    gen_title_raw = md_file.stem  # e.g., \"National Institute of Mental Health (NIMH)\"\n",
    "    gen_title_norm = normalize_title(gen_title_raw)\n",
    "\n",
    "    gold_row = df_gold[df_gold[\"title_norm\"] == gen_title_norm]\n",
    "    if gold_row.empty:\n",
    "        print(f\"⚠️ No gold match for file: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_row = gold_row.iloc[0]\n",
    "    gold_title = gold_row[\"title\"]\n",
    "\n",
    "    # Gather gold element texts\n",
    "    gold_texts = {e: gold_row.get(e, \"\").strip() for e in gold_elements if gold_row.get(e, \"\").strip()}\n",
    "    if not gold_texts:\n",
    "        print(f\"⚠️ Empty gold elements for: {gold_title}\")\n",
    "        continue\n",
    "\n",
    "    # Extract sections from generated MD\n",
    "    gen_df = extract_sections(md_file)\n",
    "    if gen_df.empty:\n",
    "        print(f\"⚠️ No sections extracted from: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    # For each gold element, compare to ALL generated sections; keep best match\n",
    "    for element, gold_text in gold_texts.items():\n",
    "        best = None\n",
    "        for _, sec in gen_df.iterrows():\n",
    "            gen_text = str(sec[\"Generated Content\"]).strip()\n",
    "            if not gen_text:\n",
    "                continue\n",
    "\n",
    "            emb_gold = sbert.encode(gold_text, convert_to_tensor=True)\n",
    "            emb_gen  = sbert.encode(gen_text,  convert_to_tensor=True)\n",
    "            sbert_sim = util.cos_sim(emb_gold, emb_gen).item()\n",
    "            rouge_l   = rouge.score(gold_text, gen_text)[\"rougeL\"].recall\n",
    "\n",
    "            cand = {\n",
    "                \"Gold Project\": gold_title,\n",
    "                \"Gold Element\": element,\n",
    "                \"Generated File\": md_file.name,\n",
    "                \"Generated Section Title\": sec[\"Section Title\"],\n",
    "                \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "                \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "            }\n",
    "            if (best is None) or (sbert_sim > best[\"SBERT_Similarity\"]):\n",
    "                best = cand\n",
    "\n",
    "        if best:\n",
    "            results.append(best)\n",
    "\n",
    "# --- Save ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n✅ Element-level similarity saved to: {out_path}\")\n",
    "print(f\"🧾 Total element–section best matches: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b457323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded full-document (26 rows)\n",
      "✅ Loaded element-level (312 rows)\n",
      "\n",
      "📊 Full-document summary table (Mean only, by Generated_File):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_File</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis of social media posts.md</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic Research from a Non-Human Source Example.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data from Human Research Participants.md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical and MRI data from human research part...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical data (human biospecimens).md</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical data from human research participants...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drug discovery including intellectual property.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene expression analysis data from non-human m...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genomic data from a non-human source.md</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genomic data from human research participants.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HeLa Cell Whole Genome Sequence (DNA or RNA).md</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human Clinical Trial Data.md</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human clinical and genomic data-NIA.md</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human clinical and genomics data.md</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human genomic data.md</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human survey data.md</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-human data (primates).md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-human data (rodents)-NIA.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Secondary Data Analysis Example.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Secondary Data Analysis on Data from Human Sub...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Secondary data analysis-NIA.md</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Secondary data analysis.md</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Survey and Interview Example.md</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Survey and interview data-NIA.md</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Survey, interview, and biological data (tiered...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Technology development.md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Generated_File SBERT ROUGE\n",
       "0                   Analysis of social media posts.md  0.76  0.39\n",
       "1   Basic Research from a Non-Human Source Example.md  0.74  0.50\n",
       "2   Clinical Data from Human Research Participants.md  0.71  0.23\n",
       "3   Clinical and MRI data from human research part...  0.73  0.29\n",
       "4               Clinical data (human biospecimens).md  0.80  0.44\n",
       "5   Clinical data from human research participants...  0.80  0.38\n",
       "6   Drug discovery including intellectual property.md  0.81  0.36\n",
       "7   Gene expression analysis data from non-human m...  0.78  0.41\n",
       "8             Genomic data from a non-human source.md  0.70  0.31\n",
       "9    Genomic data from human research participants.md  0.74  0.28\n",
       "10    HeLa Cell Whole Genome Sequence (DNA or RNA).md  0.86  0.43\n",
       "11                       Human Clinical Trial Data.md  0.72  0.32\n",
       "12             Human clinical and genomic data-NIA.md  0.82  0.45\n",
       "13                Human clinical and genomics data.md  0.66  0.42\n",
       "14                              Human genomic data.md  0.65  0.40\n",
       "15                               Human survey data.md  0.79  0.42\n",
       "16                       Non-human data (primates).md  0.71  0.32\n",
       "17                    Non-human data (rodents)-NIA.md  0.81  0.66\n",
       "18                 Secondary Data Analysis Example.md  0.81  0.43\n",
       "19  Secondary Data Analysis on Data from Human Sub...  0.75  0.45\n",
       "20                     Secondary data analysis-NIA.md  0.77  0.29\n",
       "21                         Secondary data analysis.md  0.65  0.24\n",
       "22                    Survey and Interview Example.md  0.72  0.31\n",
       "23                   Survey and interview data-NIA.md  0.79  0.42\n",
       "24  Survey, interview, and biological data (tiered...  0.79  0.36\n",
       "25                          Technology development.md  0.71  0.55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Element-level summary table (Mean ± SD):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>element_1a</td>\n",
       "      <td>0.79 ± 0.13</td>\n",
       "      <td>0.46 ± 0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>element_1b</td>\n",
       "      <td>0.72 ± 0.10</td>\n",
       "      <td>0.41 ± 0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>element_1c</td>\n",
       "      <td>0.76 ± 0.10</td>\n",
       "      <td>0.45 ± 0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>element_2</td>\n",
       "      <td>0.82 ± 0.08</td>\n",
       "      <td>0.54 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element_3</td>\n",
       "      <td>0.78 ± 0.14</td>\n",
       "      <td>0.47 ± 0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>element_4a</td>\n",
       "      <td>0.79 ± 0.11</td>\n",
       "      <td>0.59 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>element_4b</td>\n",
       "      <td>0.84 ± 0.11</td>\n",
       "      <td>0.56 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>element_4c</td>\n",
       "      <td>0.87 ± 0.08</td>\n",
       "      <td>0.60 ± 0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>element_5a</td>\n",
       "      <td>0.76 ± 0.14</td>\n",
       "      <td>0.47 ± 0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>element_5b</td>\n",
       "      <td>0.79 ± 0.12</td>\n",
       "      <td>0.45 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>element_5c</td>\n",
       "      <td>0.80 ± 0.15</td>\n",
       "      <td>0.52 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>element_6</td>\n",
       "      <td>0.86 ± 0.08</td>\n",
       "      <td>0.67 ± 0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Element        SBERT        ROUGE\n",
       "0   element_1a  0.79 ± 0.13  0.46 ± 0.29\n",
       "1   element_1b  0.72 ± 0.10  0.41 ± 0.23\n",
       "2   element_1c  0.76 ± 0.10  0.45 ± 0.29\n",
       "3    element_2  0.82 ± 0.08  0.54 ± 0.25\n",
       "4    element_3  0.78 ± 0.14  0.47 ± 0.27\n",
       "5   element_4a  0.79 ± 0.11  0.59 ± 0.28\n",
       "6   element_4b  0.84 ± 0.11  0.56 ± 0.25\n",
       "7   element_4c  0.87 ± 0.08  0.60 ± 0.27\n",
       "8   element_5a  0.76 ± 0.14  0.47 ± 0.24\n",
       "9   element_5b  0.79 ± 0.12  0.45 ± 0.25\n",
       "10  element_5c  0.80 ± 0.15  0.52 ± 0.28\n",
       "11   element_6  0.86 ± 0.08  0.67 ± 0.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saved formatted tables →\n",
      "• C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_full_table_mean_only.csv\n",
      "• C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_element_table_mean_sd.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🧮 Step 8: Summarize Evaluation Results (with Generated_File titles)\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Auto-detect project root ---\n",
    "# --------------------------------------------------------\n",
    "# 🗂️ Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ✅ change if needed\n",
    "\n",
    "EVAL_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "\n",
    "# --- Load CSVs ---\n",
    "full_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "elem_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "\n",
    "df_full = pd.read_csv(full_path)\n",
    "df_elem = pd.read_csv(elem_path)\n",
    "\n",
    "print(f\"✅ Loaded full-document ({len(df_full)} rows)\")\n",
    "print(f\"✅ Loaded element-level ({len(df_elem)} rows)\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 🧩 1️⃣ FULL-DOCUMENT LEVEL SUMMARY (Mean Only, by Generated_File)\n",
    "# ============================================================\n",
    "\n",
    "# Prefer \"Generated_File\" column; fallback to detected one\n",
    "if \"Generated_File\" in df_full.columns:\n",
    "    project_col = \"Generated_File\"\n",
    "else:\n",
    "    project_col = next(\n",
    "        (c for c in df_full.columns if \"title\" in c.lower() or \"project\" in c.lower() or \"matched\" in c.lower()),\n",
    "        df_full.columns[0],\n",
    "    )\n",
    "\n",
    "# Find numeric columns\n",
    "numeric_cols = [c for c in df_full.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "\n",
    "# Compute mean per file (if multiple rows)\n",
    "df_full_summary = (\n",
    "    df_full.groupby(project_col)[numeric_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Format to 2 decimals\n",
    "df_full_summary[\"SBERT\"] = df_full_summary[numeric_cols[0]].apply(lambda x: f\"{x:.2f}\")\n",
    "df_full_summary[\"ROUGE\"] = df_full_summary[numeric_cols[1]].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Reorder columns and rename for clarity\n",
    "df_full_table = df_full_summary[[project_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={project_col: \"Generated_File\"}\n",
    ")\n",
    "\n",
    "print(\"📊 Full-document summary table (Mean only, by Generated_File):\")\n",
    "display(df_full_table)\n",
    "\n",
    "# ============================================================\n",
    "# 🧩 2️⃣ ELEMENT-LEVEL SUMMARY (Mean ± SD)\n",
    "# ============================================================\n",
    "\n",
    "elem_col = next(\n",
    "    (c for c in df_elem.columns if \"element\" in c.lower()),\n",
    "    df_elem.columns[0],\n",
    ")\n",
    "\n",
    "numeric_cols_elem = [c for c in df_elem.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "df_elem_summary = (\n",
    "    df_elem.groupby(elem_col)[numeric_cols_elem]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "flat_cols_elem = [elem_col, \"SBERT_Mean\", \"SBERT_SD\", \"ROUGE_Mean\", \"ROUGE_SD\"]\n",
    "df_elem_summary.columns = flat_cols_elem\n",
    "\n",
    "df_elem_summary[\"SBERT\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['SBERT_Mean']:.2f} ± {r['SBERT_SD']:.2f}\", axis=1)\n",
    "df_elem_summary[\"ROUGE\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['ROUGE_Mean']:.2f} ± {r['ROUGE_SD']:.2f}\", axis=1)\n",
    "\n",
    "df_elem_table = df_elem_summary[[elem_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={elem_col: \"Element\"}\n",
    ")\n",
    "\n",
    "print(\"\\n📊 Element-level summary table (Mean ± SD):\")\n",
    "display(df_elem_table)\n",
    "\n",
    "# ============================================================\n",
    "# 💾 Save formatted tables\n",
    "# ============================================================\n",
    "out_full = EVAL_DIR / \"summary_full_table_mean_only.csv\"\n",
    "out_elem = EVAL_DIR / \"summary_element_table_mean_sd.csv\"\n",
    "\n",
    "df_full_table.to_csv(out_full, index=False)\n",
    "df_elem_table.to_csv(out_elem, index=False)\n",
    "\n",
    "print(f\"\\n💾 Saved formatted tables →\\n• {out_full}\\n• {out_elem}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
