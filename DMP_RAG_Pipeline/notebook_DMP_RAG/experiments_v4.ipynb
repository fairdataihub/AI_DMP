{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 10/08/2025\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb52b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ STEP 1 ready\n",
      "ROOT_DIR   : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "DATA_PDFS  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\pdfs\n",
      "INDEX_DIR  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss_index\n",
      "EXCEL_PATH : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "TEMPLATE_MD: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n",
      "OUTPUT_MD  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "OUTPUT_DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1 ‚Äî Imports, Config, and Helpers\n",
    "# ============================================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pypandoc  # for Markdown ‚Üí DOCX\n",
    "\n",
    "# --- LangChain Core ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Paths (works in notebook or script) ----------\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parents[1]  # when running a .py script\n",
    "except NameError:\n",
    "    ROOT_DIR = Path.cwd().parent                     # when running inside Jupyter\n",
    "\n",
    "# --- Data folders ---\n",
    "DATA_PDFS   = ROOT_DIR / \"data\" / \"pdfs\"\n",
    "INDEX_DIR   = ROOT_DIR / \"data\" / \"faiss_index\"\n",
    "EXCEL_PATH  = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "TEMPLATE_MD = ROOT_DIR / \"data\" / \"inputs\" / \"dmp-template.md\"\n",
    "\n",
    "# --- Output folders ---\n",
    "OUTPUT_MD   = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "OUTPUT_DOCX = ROOT_DIR / \"data\" / \"outputs\" / \"docx\"\n",
    "\n",
    "# --- Models / parameters ---\n",
    "\n",
    "LLM_MODEL   = \"llama3.3\"\n",
    "\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def create_folder(folderpath):\n",
    "    Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath, filename, text):\n",
    "    create_folder(folderpath)\n",
    "    (Path(folderpath) / filename).write_text(text, encoding=\"utf-8\")\n",
    "    print(\"üíæ Saved:\", Path(folderpath) / filename)\n",
    "\n",
    "def md_to_docs(md_filepath, docx_folderpath, docx_filename):\n",
    "    create_folder(docx_folderpath)\n",
    "    pypandoc.convert_file(\n",
    "        str(md_filepath), \"docx\",\n",
    "        outputfile=str(Path(docx_folderpath) / docx_filename)\n",
    "    )\n",
    "    print(\"üìÑ Converted:\", Path(docx_folderpath) / docx_filename)\n",
    "\n",
    "def clean_filename(name: str) -> str:\n",
    "    \"\"\"Remove illegal characters from filenames (Windows-safe).\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\n",
    "\n",
    "# ---------- Ensure required folders exist ----------\n",
    "for p in [DATA_PDFS, INDEX_DIR, OUTPUT_MD, OUTPUT_DOCX]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Sanity print ----------\n",
    "print(\"‚úÖ STEP 1 ready\")\n",
    "print(f\"ROOT_DIR   : {ROOT_DIR}\")\n",
    "print(f\"DATA_PDFS  : {DATA_PDFS}\")\n",
    "print(f\"INDEX_DIR  : {INDEX_DIR}\")\n",
    "print(f\"EXCEL_PATH : {EXCEL_PATH}\")\n",
    "print(f\"TEMPLATE_MD: {TEMPLATE_MD}\")\n",
    "print(f\"OUTPUT_MD  : {OUTPUT_MD}\")\n",
    "print(f\"OUTPUT_DOCX: {OUTPUT_DOCX}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687935b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Loading cached chunks from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss_index\\chunks_cache.pkl\n",
      "‚úÖ STEP 2 ready ‚Äî 955866 chunks loaded.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 2 ‚Äî Load PDFs and TXT Files, Split into Text Chunks (Cached)\n",
    "# =========================================================\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Optional: Silence PDFMiner warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pdfminer\")\n",
    "\n",
    "# --- Paths based on your system ---\n",
    "ROOT_DIR = Path(r\"c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")\n",
    "DATA_PDFS = ROOT_DIR / \"data\" / \"pdfs\"\n",
    "INDEX_DIR = ROOT_DIR / \"data\" / \"faiss_index\"\n",
    "CHUNK_CACHE_PATH = INDEX_DIR / \"chunks_cache.pkl\"\n",
    "\n",
    "# --- Ensure folders exist ---\n",
    "DATA_PDFS.mkdir(parents=True, exist_ok=True)\n",
    "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Load PDFs and TXT files\n",
    "# --------------------------------------------------------\n",
    "def load_docs_from_folder(folder: Path):\n",
    "    \"\"\"Load all PDF and TXT files as LangChain Document objects.\"\"\"\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå Folder not found: {folder}\")\n",
    "\n",
    "    pdf_files = sorted(folder.glob(\"*.pdf\"))\n",
    "    txt_files = sorted(folder.glob(\"*.txt\"))\n",
    "    all_files = pdf_files + txt_files\n",
    "    if not all_files:\n",
    "        print(f\"‚ö†Ô∏è No PDF or TXT files found in {folder}. Please add some files.\")\n",
    "        return []\n",
    "\n",
    "    docs = []\n",
    "    for fpath in tqdm(all_files, desc=f\"üìÑ Loading files from {folder}\"):\n",
    "        try:\n",
    "            if fpath.suffix.lower() == \".pdf\":\n",
    "                loader = PyPDFLoader(str(fpath))\n",
    "            elif fpath.suffix.lower() == \".txt\":\n",
    "                loader = TextLoader(str(fpath), encoding=\"utf-8\")\n",
    "            else:\n",
    "                print(f\"‚è≠Ô∏è Skipped unsupported file: {fpath.name}\")\n",
    "                continue\n",
    "            docs.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {fpath.name}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Loaded {len(docs)} pages from {len(all_files)} files in '{folder}'.\")\n",
    "    return docs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Split documents into chunks\n",
    "# --------------------------------------------------------\n",
    "def split_into_chunks(docs, chunk_size=800, chunk_overlap=120):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(f\"üß© Created {len(chunks)} chunks from {len(docs)} document pages.\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Load or Create Cached Chunks\n",
    "# --------------------------------------------------------\n",
    "def load_or_create_chunks(folder=DATA_PDFS, cache_path=CHUNK_CACHE_PATH):\n",
    "    \"\"\"Load cached chunks if available; otherwise load, split, and cache.\"\"\"\n",
    "    if cache_path.exists():\n",
    "        print(f\"‚ö° Loading cached chunks from {cache_path}\")\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            chunks = pickle.load(f)\n",
    "    else:\n",
    "        print(\"üïí No cache found ‚Äî processing documents...\")\n",
    "        raw_docs = load_docs_from_folder(folder)\n",
    "        if not raw_docs:\n",
    "            return []  # exit early if folder empty\n",
    "        chunks = split_into_chunks(raw_docs)\n",
    "        cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump(chunks, f)\n",
    "        print(f\"üíæ Saved chunks cache ‚Üí {cache_path}\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Example Run\n",
    "# --------------------------------------------------------\n",
    "chunks = load_or_create_chunks()\n",
    "print(f\"‚úÖ STEP 2 ready ‚Äî {len(chunks)} chunks loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa20d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.0\n",
      "Uninstalling torch-2.9.0:\n",
      "  Successfully uninstalled torch-2.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\~orch'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch torchvision torchaudio -y\n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0f00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Using device: CPU\n",
      "üß± Building new FAISS HNSW index on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üî¢ Embedding text chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 955866/955866 [00:00<00:00, 3375551.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# --- Execute step ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m vectorstore = \u001b[43mbuild_or_load_faiss_hnsw_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINDEX_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# --- Configure retriever with MMR re-ranking ---\u001b[39;00m\n\u001b[32m     95\u001b[39m retriever = vectorstore.as_retriever(\n\u001b[32m     96\u001b[39m     search_type=\u001b[33m\"\u001b[39m\u001b[33mmmr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     search_kwargs={\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     }\n\u001b[32m    102\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mbuild_or_load_faiss_hnsw_index\u001b[39m\u001b[34m(index_dir, chunks)\u001b[39m\n\u001b[32m     74\u001b[39m     index_used = cpu_index\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# --- Create FAISS store from documents ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43müî¢ Embedding text chunks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_used\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# --- Save the index locally ---\u001b[39;00m\n\u001b[32m     84\u001b[39m vectorstore.save_local(\u001b[38;5;28mstr\u001b[39m(index_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:837\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    835\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:115\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    113\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:588\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m     attention_output = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    586\u001b[39m     outputs = outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:596\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:512\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================ \n",
    "# STEP 3 ‚Äî Build or Load FAISS (HNSW) Index\n",
    "# ============================================\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Parameters ---\n",
    "TOP_K = 8\n",
    "EMBED_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "INDEX_DIR = Path(\"data/index/faiss_hnsw\")\n",
    "\n",
    "# --- Auto-detect GPU or CPU ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üíª Using device: {DEVICE.upper()}\")\n",
    "\n",
    "# --- Initialize embedding model (auto device selection) ---\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs={\"device\": DEVICE},\n",
    "    encode_kwargs={\"batch_size\": 64 if DEVICE == \"cuda\" else 16}\n",
    ")\n",
    "\n",
    "def build_or_load_faiss_hnsw_index(index_dir=INDEX_DIR, chunks=None):\n",
    "    \"\"\"\n",
    "    Builds or loads a FAISS HNSW index.\n",
    "    If no index exists, creates a new one from text chunks.\n",
    "    Automatically uses GPU if available.\n",
    "    \"\"\"\n",
    "    faiss_path = index_dir / \"index.faiss\"\n",
    "    pkl_path   = index_dir / \"index.pkl\"\n",
    "\n",
    "    # --- Load existing index if found ---\n",
    "    if faiss_path.exists() and pkl_path.exists():\n",
    "        print(\"üì¶ Existing FAISS HNSW index found. Loading from disk...\")\n",
    "        vectorstore = FAISS.load_local(\n",
    "            str(index_dir),\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\"‚úÖ FAISS HNSW index loaded successfully.\")\n",
    "        return vectorstore\n",
    "\n",
    "    # --- Validate chunks ---\n",
    "    if chunks is None or len(chunks) == 0:\n",
    "        raise RuntimeError(\"‚ùå No chunks provided. Please run Step 2 first to load and split text.\")\n",
    "\n",
    "    print(f\"üß± Building new FAISS HNSW index on {DEVICE.upper()}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Initialize HNSW index ---\n",
    "    d = len(embeddings.embed_query(\"sample\"))\n",
    "    cpu_index = faiss.IndexHNSWFlat(d, 32)\n",
    "    cpu_index.hnsw.efConstruction = 200\n",
    "    cpu_index.hnsw.efSearch = 50\n",
    "\n",
    "    # --- Move to GPU if available ---\n",
    "    if DEVICE == \"cuda\":\n",
    "        try:\n",
    "            res = faiss.StandardGpuResources()\n",
    "            gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index)\n",
    "            index_used = gpu_index\n",
    "            print(\"‚ö° Using FAISS GPU index.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è GPU FAISS initialization failed: {e}\")\n",
    "            print(\"‚û°Ô∏è Falling back to CPU FAISS index.\")\n",
    "            index_used = cpu_index\n",
    "    else:\n",
    "        index_used = cpu_index\n",
    "\n",
    "    # --- Create FAISS store from documents ---\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        tqdm(chunks, desc=\"üî¢ Embedding text chunks\"),\n",
    "        embeddings,\n",
    "        index=index_used\n",
    "    )\n",
    "\n",
    "    # --- Save the index locally ---\n",
    "    vectorstore.save_local(str(index_dir))\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"üíæ Saved FAISS HNSW index to {index_dir}\")\n",
    "    print(f\"‚è±Ô∏è Build completed in {duration/60:.2f} min ({duration:.1f} sec)\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# --- Execute step ---\n",
    "vectorstore = build_or_load_faiss_hnsw_index(INDEX_DIR, chunks)\n",
    "\n",
    "# --- Configure retriever with MMR re-ranking ---\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": TOP_K,            # number of final results\n",
    "        \"fetch_k\": 2 * TOP_K,  # candidate pool before MMR filtering\n",
    "        \"lambda_mult\": 0.5     # relevance-diversity tradeoff\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Retriever ready (FAISS HNSW + {DEVICE.upper()} + MMR enabled, top_k={TOP_K})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Excel loaded successfully: 26 rows\n",
      "‚úÖ DMP Markdown template loaded.\n",
      "üîó RAG chain initialized with model: llama3.3\n",
      "‚úÖ RAG chain ready for generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahid\\AppData\\Local\\Temp\\ipykernel_49552\\51411919.py:31: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=llm_model)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 4 ‚Äî Load Excel, Template, and Build RAG Chain (Fixed)\n",
    "# ============================================\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load Excel file ---\n",
    "if not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Excel file not found: {EXCEL_PATH}\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(f\"‚úÖ Excel loaded successfully: {len(df)} rows\")\n",
    "\n",
    "# --- Load Markdown Template ---\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Template file not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(\"‚úÖ DMP Markdown template loaded.\")\n",
    "\n",
    "\n",
    "# --- Build RAG chain ---\n",
    "def build_rag_chain(retriever, llm_model=LLM_MODEL):\n",
    "    \"\"\"\n",
    "    Build a flexible RAG pipeline that retrieves context\n",
    "    and generates a context-grounded NIH DMP section.\n",
    "    \"\"\"\n",
    "    llm = Ollama(model=llm_model)\n",
    "\n",
    "    prompt_template = \"\"\"You are an expert biomedical data steward and grant writer.\n",
    "Create a high-quality NIH Data Management and Sharing Plan (DMSP)\n",
    "based on the retrieved NIH context and the user's query.\n",
    "\n",
    "----\n",
    "Context from NIH Repository:\n",
    "{context}\n",
    "\n",
    "----\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Use the context above and follow the NIH template structure. Write fluently and cohesively.\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    def format_docs(docs):\n",
    "        \"\"\"Format retrieved documents into clean text.\"\"\"\n",
    "        if not docs:\n",
    "            return \"\"\n",
    "        formatted = []\n",
    "        for d in docs:\n",
    "            page = d.metadata.get(\"page\", \"\")\n",
    "            title = d.metadata.get(\"source\", \"\")\n",
    "            formatted.append(f\"[Page {page}] {title}\\n{d.page_content.strip()}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    print(f\"üîó RAG chain initialized with model: {llm_model}\")\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "# --- Initialize the RAG chain ---\n",
    "rag_chain = build_rag_chain(retriever)\n",
    "print(\"‚úÖ RAG chain ready for generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded input Excel ‚Äî 26 rows\n",
      "‚úÖ Loaded NIH DMP Markdown template from: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Generating DMP for: Clinical and MRI data from human research participants\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahid\\AppData\\Local\\Temp\\ipykernel_49552\\2591499688.py:74: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 5 ‚Äî RAG-Based DMP Generation Using Titles\n",
    "# ============================================\n",
    "import re, pandas as pd, pypandoc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Paths ----------\n",
    "EXCEL_PATH = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "OUTPUT_LOG = ROOT_DIR / \"data\" / \"outputs\" / \"rag_generated_dmp_log.csv\"\n",
    "OUTPUT_MD.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DOCX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load Excel ----------\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(f\"‚úÖ Loaded input Excel ‚Äî {len(df)} rows\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# ---------- Verify template ----------\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Template not found: {TEMPLATE_MD}\")\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Loaded NIH DMP Markdown template from: {TEMPLATE_MD}\")\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"Replace illegal filename characters but preserve readable title.\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name.strip())\n",
    "\n",
    "def create_folder(folderpath: Path):\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath: Path, filename: str, response: str):\n",
    "    create_folder(folderpath)\n",
    "    filepath = folderpath / filename\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)\n",
    "    print(f\"üíæ Saved: {filepath}\")\n",
    "\n",
    "def md_to_docx(md_filepath: Path, docx_folder: Path, docx_filename: str):\n",
    "    create_folder(docx_folder)\n",
    "    docx_path = docx_folder / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(docx_path))\n",
    "    print(f\"üìÑ Converted: {docx_path}\")\n",
    "\n",
    "# ---------- Main Generation ----------\n",
    "records = []\n",
    "TOP_K = 6  # retrieved context chunks\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"üß† Generating NIH DMPs\"):\n",
    "    title = str(row[\"title\"]).strip()\n",
    "    print(f\"\\nüß© Generating DMP for: {title}\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Build query from Excel elements\n",
    "    element_texts = []\n",
    "    for col in [c for c in df.columns if c.startswith(\"element\")]:\n",
    "        val = str(row[col]).strip()\n",
    "        if val:\n",
    "            element_texts.append(f\"{col.upper()}: {val}\")\n",
    "    query_data = \"\\n\".join(element_texts)\n",
    "\n",
    "    query = (\n",
    "        f\"You are an expert biomedical data steward and grant writer. \"\n",
    "        f\"Create a complete NIH Data Management and Sharing Plan (DMSP) for the project titled '{title}'. \"\n",
    "        f\"Use retrieved context from the NIH corpus to fill in all template sections accurately.\\n\\n\"\n",
    "        f\"Here is background information from the proposal:\\n{query_data}\\n\"\n",
    "    )\n",
    "\n",
    "    # 2Ô∏è‚É£ Retrieve context from FAISS\n",
    "    try:\n",
    "        retrieved_docs = retriever.get_relevant_documents(query)\n",
    "        context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs[:TOP_K])\n",
    "        print(f\"üîé Retrieved {len(retrieved_docs)} context chunks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Retrieval failed for {title}: {e}\")\n",
    "        context_text = \"\"\n",
    "\n",
    "    # 3Ô∏è‚É£ Combine context, query, and template\n",
    "    full_prompt = f\"\"\"\n",
    "You are an expert biomedical data steward and grant writer.\n",
    "Use the retrieved NIH context and the provided template to generate a complete Data Management and Sharing Plan.\n",
    "\n",
    "----\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "----\n",
    "Project Query:\n",
    "{query}\n",
    "\n",
    "Use the following NIH DMSP Markdown template. Do not alter section titles:\n",
    "{dmp_template_text}\n",
    "\"\"\"\n",
    "\n",
    "    # 4Ô∏è‚É£ Run through RAG model\n",
    "    try:\n",
    "        response = rag_chain.invoke(full_prompt)\n",
    "\n",
    "        # 5Ô∏è‚É£ Save using SAME TITLE as in Excel\n",
    "        safe_title = sanitize_filename(title)\n",
    "        md_filename = f\"{safe_title}.md\"\n",
    "        docx_filename = f\"{safe_title}.docx\"\n",
    "        md_path = OUTPUT_MD / md_filename\n",
    "\n",
    "        save_md(OUTPUT_MD, md_filename, response)\n",
    "        md_to_docx(md_path, OUTPUT_DOCX, docx_filename)\n",
    "\n",
    "        # 6Ô∏è‚É£ Log summary\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": response[:1000],\n",
    "            \"Error\": \"\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating DMP for {title}: {e}\")\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": \"\",\n",
    "            \"Error\": str(e)\n",
    "        })\n",
    "\n",
    "# ---------- Save Log ----------\n",
    "pd.DataFrame(records).to_csv(OUTPUT_LOG, index=False, encoding=\"utf-8\")\n",
    "print(\"\\n‚úÖ All NIH DMPs generated successfully ‚Äî titles preserved exactly as in Excel!\")\n",
    "print(f\"üìä CSV log saved to: {OUTPUT_LOG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58c3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Gold PDF folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\gold_dmps\n",
      "üìò Generated Markdown folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "üöÄ Loading models...\n",
      "‚úÖ Models ready.\n",
      "üìä Found 26 generated DMPs and 26 gold PDFs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:   4%|‚ñç         | 1/26 [00:00<00:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Analysis of social media posts.md ‚Üî 26-Analysis of social media posts-NCI.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:   8%|‚ñä         | 2/26 [00:00<00:08,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Basic Research from a Non-Human Source Example.md ‚Üî 11-Basic Research from a Non-Human Source Example-NIDDK.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  12%|‚ñà‚ñè        | 3/26 [00:01<00:11,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical and MRI data from human research participants.md ‚Üî 1-Clinical andor MRI data from human research participants-NIMH.pdf (score=0.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  15%|‚ñà‚ñå        | 4/26 [00:01<00:10,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical data (human biospecimens).md ‚Üî 22-Clinical data (human biospecimens)-NIA.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  19%|‚ñà‚ñâ        | 5/26 [00:02<00:09,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical data from human research participants-NIA.md ‚Üî 15-Clinical data from human research participants-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:02<00:07,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical Data from Human Research Participants.md ‚Üî 15-Clinical data from human research participants-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:02<00:07,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Drug discovery including intellectual property.md ‚Üî 23-Drug discovery including intellectual property-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:03<00:06,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Gene expression analysis data from non-human model organism (zebrafish).md ‚Üî 8-Gene expression analysis data from non-human model organism (zebrafish)-NICHD.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:03<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Genomic data from a non-human source.md ‚Üî 3-Genomic data from a non-human source-NIMH.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:04<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Genomic data from human research participants.md ‚Üî 2-Genomic data from human research participants-NIMH.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:04<00:06,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched HeLa Cell Whole Genome Sequence (DNA or RNA).md ‚Üî 24-HeLa Cell Whole Genome Sequence (DNA or RNA)-OD, NHGRI.pdf (score=0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:05<00:06,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human clinical and genomic data-NIA.md ‚Üî 20-Human clinical and genomic data-NIA.pdf (score=0.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:05<00:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human clinical and genomics data.md ‚Üî 7-Human clinical and genomics data-NICHD.pdf (score=0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:06<00:06,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human Clinical Trial Data.md ‚Üî 14-Human Clinical Trial Data-NICHD.pdf (score=0.85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:06<00:05,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human genomic data.md ‚Üî 5-Human genomic data-NHGRI.pdf (score=0.82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:07<00:04,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human survey data.md ‚Üî 9-Human survey data-NICHD.pdf (score=0.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:07<00:03,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Non-human data (primates).md ‚Üî 17-Non-human data (primates)-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:07<00:03,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Non-human data (rodents)-NIA.md ‚Üî 21-Non-human data (rodents)-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:08<00:02,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary Data Analysis Example.md ‚Üî 12-Secondary Data Analysis Example-NIDDK.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:08<00:02,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary Data Analysis on Data from Human Subjects-NIA.md ‚Üî 25-Secondary Data Analysis on Data from Human Subjects-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:09<00:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary data analysis-NIA.md ‚Üî 18-Secondary data analysis-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:09<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary data analysis.md ‚Üî 18-Secondary data analysis-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:09<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey and interview data-NIA.md ‚Üî 19-Survey and interview data-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:10<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey and Interview Example.md ‚Üî 13-Survey and Interview Example-NHGRI.pdf (score=0.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:10<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey, interview, and biological data (tiered access).md ‚Üî 16-Survey, interview, and biological data (tiered access)-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:10<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Technology development.md ‚Üî 6-Technology development-NHGRI.pdf (score=0.85)\n",
      "\n",
      "‚úÖ Markdown‚ÄìPDF (fuzzy) similarity results saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\full_dmp_pdf_comparison_fuzzy.csv\n",
      "üßæ Total matched DMP pairs: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 7 ‚Äî Full DMP Comparison: Markdown (Generated) vs PDF (Gold, Fuzzy Matching)\n",
    "# ============================================\n",
    "import os, re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "# --- Paths ---\n",
    "GOLD_DIR      = ROOT_DIR / \"data\" /\"inputs\"/ \"gold_dmps\"      # PDF gold-standard DMPs\n",
    "GENERATED_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"      # Generated DMPs\n",
    "EVAL_DIR      = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìó Gold PDF folder: {GOLD_DIR}\")\n",
    "print(f\"üìò Generated Markdown folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"üöÄ Loading models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"‚úÖ Models ready.\")\n",
    "\n",
    "# --- Helper functions ---\n",
    "def normalize_name(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove markdown or formatting artifacts.\"\"\"\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"#+\\s*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*|\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract readable text from PDF using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading {pdf_path.name}: {e}\")\n",
    "    return clean_text(text)\n",
    "\n",
    "def chunk_text(text, size=300):\n",
    "    \"\"\"Split long text into 300-word chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "def compare_chunked(gold_text, gen_text, model):\n",
    "    \"\"\"Chunked SBERT + ROUGE similarity between two long texts.\"\"\"\n",
    "    gold_chunks = chunk_text(gold_text)\n",
    "    gen_chunks = chunk_text(gen_text)\n",
    "\n",
    "    sbert_scores, rouge_scores = [], []\n",
    "    for g in gold_chunks:\n",
    "        emb_g = model.encode(g, convert_to_tensor=True)\n",
    "        chunk_sims = []\n",
    "        for gen in gen_chunks:\n",
    "            emb_gen = model.encode(gen, convert_to_tensor=True)\n",
    "            chunk_sims.append(util.cos_sim(emb_g, emb_gen).item())\n",
    "        sbert_scores.append(max(chunk_sims))  # best match per gold chunk\n",
    "\n",
    "        rouge_chunk_scores = [rouge.score(g, gen)[\"rougeL\"].recall for gen in gen_chunks]\n",
    "        rouge_scores.append(max(rouge_chunk_scores))\n",
    "\n",
    "    return np.mean(sbert_scores), np.mean(rouge_scores)\n",
    "\n",
    "def best_fuzzy_match(target, gold_names, threshold=0.6):\n",
    "    \"\"\"Find best matching name among gold files using fuzzy ratio.\"\"\"\n",
    "    best_match, best_score = None, 0\n",
    "    for g in gold_names:\n",
    "        score = SequenceMatcher(None, target, g).ratio()\n",
    "        if score > best_score:\n",
    "            best_match, best_score = g, score\n",
    "    return (best_match, best_score) if best_score >= threshold else (None, best_score)\n",
    "\n",
    "# --- Collect gold PDFs and generated MDs ---\n",
    "gold_files = {normalize_name(f.stem): f for f in GOLD_DIR.glob(\"*.pdf\")}\n",
    "gen_files  = {normalize_name(f.stem): f for f in GENERATED_DIR.glob(\"*.md\")}\n",
    "print(f\"üìä Found {len(gen_files)} generated DMPs and {len(gold_files)} gold PDFs.\")\n",
    "\n",
    "# --- Compare all matching files ---\n",
    "results = []\n",
    "for name, gen_path in tqdm(gen_files.items(), desc=\"üîé Matching & Comparing DMPs\"):\n",
    "    best_match, score = best_fuzzy_match(name, list(gold_files.keys()))\n",
    "    if not best_match:\n",
    "        print(f\"‚ö†Ô∏è No gold match for: {gen_path.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_path = gold_files[best_match]\n",
    "    gold_text = extract_text_from_pdf(gold_path)\n",
    "    gen_text  = clean_text(gen_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    if not gold_text.strip() or not gen_text.strip():\n",
    "        print(f\"‚ö†Ô∏è Skipping empty file: {name}\")\n",
    "        continue\n",
    "\n",
    "    sbert_sim, rouge_l = compare_chunked(gold_text, gen_text, sbert)\n",
    "    results.append({\n",
    "        \"Generated_File\": gen_path.name,\n",
    "        \"Matched_Gold_PDF\": gold_path.name,\n",
    "        \"Match_Score\": round(score, 3),\n",
    "        \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "        \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "    })\n",
    "    print(f\"‚úÖ Matched {gen_path.name} ‚Üî {gold_path.name} (score={score:.2f})\")\n",
    "\n",
    "# --- Save results ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "df_results.to_csv(out_path, index=False)\n",
    "print(f\"\\n‚úÖ Markdown‚ÄìPDF (fuzzy) similarity results saved to: {out_path}\")\n",
    "print(f\"üßæ Total matched DMP pairs: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ROOT_DIR set to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "üìó Gold Excel: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "üìò Generated MD folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "‚úÖ Loaded 26 gold projects.\n",
      "üöÄ Loading evaluation models...\n",
      "‚úÖ Models ready.\n",
      "üîç Found 26 generated Markdown files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìä Comparing element-level: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:57<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Element-level similarity saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\element_similarity_exact_titles.csv\n",
      "üßæ Total element‚Äìsection best matches: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 7 ‚Äî Element-Level Comparison with NIH Gold Standard (Exact Title Match)\n",
    "# ============================================\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --- Paths ---\n",
    "# --- Define ROOT_DIR dynamically (project root) ---\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "print(f\"üìÇ ROOT_DIR set to: {ROOT_DIR}\")\n",
    "GOLD_PATH      = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "GENERATED_DIR  = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "EVAL_DIR       = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìó Gold Excel: {GOLD_PATH}\")\n",
    "print(f\"üìò Generated MD folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Load gold reference (Excel) ---\n",
    "df_gold = pd.read_excel(GOLD_PATH)\n",
    "df_gold.columns = df_gold.columns.str.strip().str.lower()\n",
    "df_gold = df_gold.fillna(\"\").astype(str)\n",
    "\n",
    "def normalize_title(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "df_gold[\"title_norm\"] = df_gold[\"title\"].apply(normalize_title)\n",
    "\n",
    "gold_elements = [\n",
    "    \"element_1a\",\"element_1b\",\"element_1c\",\n",
    "    \"element_2\",\"element_3\",\n",
    "    \"element_4a\",\"element_4b\",\"element_4c\",\n",
    "    \"element_5a\",\"element_5b\",\"element_5c\",\n",
    "    \"element_6\"\n",
    "]\n",
    "print(f\"‚úÖ Loaded {len(df_gold)} gold projects.\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"üöÄ Loading evaluation models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"‚úÖ Models ready.\")\n",
    "\n",
    "# --- Markdown parsing helpers ---\n",
    "def is_title(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    # Accept markdown headers (#, ##, ...) OR numbered bold section titles like \"1. **Data Types**\"\n",
    "    return s.startswith(\"#\") or bool(re.match(r\"^\\s*\\d*\\.?\\s*\\*\\*.*\\*\\*\\s*$\", s))\n",
    "\n",
    "def extract_sections(md_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract {Section Title, Generated Content} pairs from a Markdown file.\n",
    "    Also strips any <think>...</think> blocks if present.\n",
    "    \"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\")\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    entries, current_title, buf = [], None, []\n",
    "\n",
    "    for ln in lines:\n",
    "        if is_title(ln):\n",
    "            if current_title and any(x.strip() for x in buf):\n",
    "                entries.append({\n",
    "                    \"Section Title\": current_title.strip(),\n",
    "                    \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "                })\n",
    "            current_title, buf = ln, []\n",
    "        else:\n",
    "            buf.append(ln)\n",
    "\n",
    "    if current_title and any(x.strip() for x in buf):\n",
    "        entries.append({\n",
    "            \"Section Title\": current_title.strip(),\n",
    "            \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# --- Compare (exact title match) ---\n",
    "results = []\n",
    "md_files = sorted(GENERATED_DIR.glob(\"*.md\"))\n",
    "print(f\"üîç Found {len(md_files)} generated Markdown files.\")\n",
    "\n",
    "for md_file in tqdm(md_files, desc=\"üìä Comparing element-level\"):\n",
    "    # Your MD files are saved with the SAME title (sanitized) ‚Äî reverse-sanitize to match Excel\n",
    "    # We‚Äôll normalize both sides and do exact equality on normalized strings\n",
    "    gen_title_raw = md_file.stem  # e.g., \"National Institute of Mental Health (NIMH)\"\n",
    "    gen_title_norm = normalize_title(gen_title_raw)\n",
    "\n",
    "    gold_row = df_gold[df_gold[\"title_norm\"] == gen_title_norm]\n",
    "    if gold_row.empty:\n",
    "        print(f\"‚ö†Ô∏è No gold match for file: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_row = gold_row.iloc[0]\n",
    "    gold_title = gold_row[\"title\"]\n",
    "\n",
    "    # Gather gold element texts\n",
    "    gold_texts = {e: gold_row.get(e, \"\").strip() for e in gold_elements if gold_row.get(e, \"\").strip()}\n",
    "    if not gold_texts:\n",
    "        print(f\"‚ö†Ô∏è Empty gold elements for: {gold_title}\")\n",
    "        continue\n",
    "\n",
    "    # Extract sections from generated MD\n",
    "    gen_df = extract_sections(md_file)\n",
    "    if gen_df.empty:\n",
    "        print(f\"‚ö†Ô∏è No sections extracted from: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    # For each gold element, compare to ALL generated sections; keep best match\n",
    "    for element, gold_text in gold_texts.items():\n",
    "        best = None\n",
    "        for _, sec in gen_df.iterrows():\n",
    "            gen_text = str(sec[\"Generated Content\"]).strip()\n",
    "            if not gen_text:\n",
    "                continue\n",
    "\n",
    "            emb_gold = sbert.encode(gold_text, convert_to_tensor=True)\n",
    "            emb_gen  = sbert.encode(gen_text,  convert_to_tensor=True)\n",
    "            sbert_sim = util.cos_sim(emb_gold, emb_gen).item()\n",
    "            rouge_l   = rouge.score(gold_text, gen_text)[\"rougeL\"].recall\n",
    "\n",
    "            cand = {\n",
    "                \"Gold Project\": gold_title,\n",
    "                \"Gold Element\": element,\n",
    "                \"Generated File\": md_file.name,\n",
    "                \"Generated Section Title\": sec[\"Section Title\"],\n",
    "                \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "                \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "            }\n",
    "            if (best is None) or (sbert_sim > best[\"SBERT_Similarity\"]):\n",
    "                best = cand\n",
    "\n",
    "        if best:\n",
    "            results.append(best)\n",
    "\n",
    "# --- Save ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Element-level similarity saved to: {out_path}\")\n",
    "print(f\"üßæ Total element‚Äìsection best matches: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b457323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded full-document (26 rows)\n",
      "‚úÖ Loaded element-level (312 rows)\n",
      "\n",
      "üìä Full-document summary table (Mean only, by Generated_File):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_File</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis of social media posts.md</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic Research from a Non-Human Source Example.md</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data from Human Research Participants.md</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical and MRI data from human research part...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical data (human biospecimens).md</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical data from human research participants...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drug discovery including intellectual property.md</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene expression analysis data from non-human m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genomic data from a non-human source.md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genomic data from human research participants.md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HeLa Cell Whole Genome Sequence (DNA or RNA).md</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human Clinical Trial Data.md</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human clinical and genomic data-NIA.md</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human clinical and genomics data.md</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human genomic data.md</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human survey data.md</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-human data (primates).md</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-human data (rodents)-NIA.md</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Secondary Data Analysis Example.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Secondary Data Analysis on Data from Human Sub...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Secondary data analysis-NIA.md</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Secondary data analysis.md</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Survey and Interview Example.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Survey and interview data-NIA.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Survey, interview, and biological data (tiered...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Technology development.md</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Generated_File SBERT ROUGE\n",
       "0                   Analysis of social media posts.md  0.78  0.39\n",
       "1   Basic Research from a Non-Human Source Example.md  0.86  0.54\n",
       "2   Clinical Data from Human Research Participants.md  0.68  0.24\n",
       "3   Clinical and MRI data from human research part...  0.75  0.33\n",
       "4               Clinical data (human biospecimens).md  0.82  0.42\n",
       "5   Clinical data from human research participants...  0.77  0.41\n",
       "6   Drug discovery including intellectual property.md  0.80  0.41\n",
       "7   Gene expression analysis data from non-human m...  0.80  0.40\n",
       "8             Genomic data from a non-human source.md  0.71  0.34\n",
       "9    Genomic data from human research participants.md  0.71  0.29\n",
       "10    HeLa Cell Whole Genome Sequence (DNA or RNA).md  0.87  0.44\n",
       "11                       Human Clinical Trial Data.md  0.68  0.29\n",
       "12             Human clinical and genomic data-NIA.md  0.83  0.45\n",
       "13                Human clinical and genomics data.md  0.68  0.44\n",
       "14                              Human genomic data.md  0.69  0.40\n",
       "15                               Human survey data.md  0.70  0.30\n",
       "16                       Non-human data (primates).md  0.78  0.30\n",
       "17                    Non-human data (rodents)-NIA.md  0.85  0.54\n",
       "18                 Secondary Data Analysis Example.md  0.74  0.45\n",
       "19  Secondary Data Analysis on Data from Human Sub...  0.82  0.33\n",
       "20                     Secondary data analysis-NIA.md  0.75  0.32\n",
       "21                         Secondary data analysis.md  0.66  0.30\n",
       "22                    Survey and Interview Example.md  0.74  0.32\n",
       "23                   Survey and interview data-NIA.md  0.74  0.33\n",
       "24  Survey, interview, and biological data (tiered...  0.77  0.38\n",
       "25                          Technology development.md  0.63  0.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Element-level summary table (Mean ¬± SD):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>element_1a</td>\n",
       "      <td>0.81 ¬± 0.13</td>\n",
       "      <td>0.49 ¬± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>element_1b</td>\n",
       "      <td>0.73 ¬± 0.11</td>\n",
       "      <td>0.46 ¬± 0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>element_1c</td>\n",
       "      <td>0.78 ¬± 0.11</td>\n",
       "      <td>0.53 ¬± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>element_2</td>\n",
       "      <td>0.80 ¬± 0.10</td>\n",
       "      <td>0.49 ¬± 0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element_3</td>\n",
       "      <td>0.77 ¬± 0.13</td>\n",
       "      <td>0.49 ¬± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>element_4a</td>\n",
       "      <td>0.80 ¬± 0.10</td>\n",
       "      <td>0.56 ¬± 0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>element_4b</td>\n",
       "      <td>0.82 ¬± 0.10</td>\n",
       "      <td>0.53 ¬± 0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>element_4c</td>\n",
       "      <td>0.87 ¬± 0.10</td>\n",
       "      <td>0.61 ¬± 0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>element_5a</td>\n",
       "      <td>0.76 ¬± 0.12</td>\n",
       "      <td>0.47 ¬± 0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>element_5b</td>\n",
       "      <td>0.80 ¬± 0.11</td>\n",
       "      <td>0.46 ¬± 0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>element_5c</td>\n",
       "      <td>0.79 ¬± 0.12</td>\n",
       "      <td>0.51 ¬± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>element_6</td>\n",
       "      <td>0.87 ¬± 0.07</td>\n",
       "      <td>0.64 ¬± 0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Element        SBERT        ROUGE\n",
       "0   element_1a  0.81 ¬± 0.13  0.49 ¬± 0.31\n",
       "1   element_1b  0.73 ¬± 0.11  0.46 ¬± 0.23\n",
       "2   element_1c  0.78 ¬± 0.11  0.53 ¬± 0.28\n",
       "3    element_2  0.80 ¬± 0.10  0.49 ¬± 0.21\n",
       "4    element_3  0.77 ¬± 0.13  0.49 ¬± 0.25\n",
       "5   element_4a  0.80 ¬± 0.10  0.56 ¬± 0.23\n",
       "6   element_4b  0.82 ¬± 0.10  0.53 ¬± 0.23\n",
       "7   element_4c  0.87 ¬± 0.10  0.61 ¬± 0.26\n",
       "8   element_5a  0.76 ¬± 0.12  0.47 ¬± 0.29\n",
       "9   element_5b  0.80 ¬± 0.11  0.46 ¬± 0.20\n",
       "10  element_5c  0.79 ¬± 0.12  0.51 ¬± 0.31\n",
       "11   element_6  0.87 ¬± 0.07  0.64 ¬± 0.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved formatted tables ‚Üí\n",
      "‚Ä¢ C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_full_table_mean_only.csv\n",
      "‚Ä¢ C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_element_table_mean_sd.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üßÆ Step 8: Summarize Evaluation Results (with Generated_File titles)\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Auto-detect project root ---\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "EVAL_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "\n",
    "# --- Load CSVs ---\n",
    "full_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "elem_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "\n",
    "df_full = pd.read_csv(full_path)\n",
    "df_elem = pd.read_csv(elem_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded full-document ({len(df_full)} rows)\")\n",
    "print(f\"‚úÖ Loaded element-level ({len(df_elem)} rows)\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# üß© 1Ô∏è‚É£ FULL-DOCUMENT LEVEL SUMMARY (Mean Only, by Generated_File)\n",
    "# ============================================================\n",
    "\n",
    "# Prefer \"Generated_File\" column; fallback to detected one\n",
    "if \"Generated_File\" in df_full.columns:\n",
    "    project_col = \"Generated_File\"\n",
    "else:\n",
    "    project_col = next(\n",
    "        (c for c in df_full.columns if \"title\" in c.lower() or \"project\" in c.lower() or \"matched\" in c.lower()),\n",
    "        df_full.columns[0],\n",
    "    )\n",
    "\n",
    "# Find numeric columns\n",
    "numeric_cols = [c for c in df_full.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "\n",
    "# Compute mean per file (if multiple rows)\n",
    "df_full_summary = (\n",
    "    df_full.groupby(project_col)[numeric_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Format to 2 decimals\n",
    "df_full_summary[\"SBERT\"] = df_full_summary[numeric_cols[0]].apply(lambda x: f\"{x:.2f}\")\n",
    "df_full_summary[\"ROUGE\"] = df_full_summary[numeric_cols[1]].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Reorder columns and rename for clarity\n",
    "df_full_table = df_full_summary[[project_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={project_col: \"Generated_File\"}\n",
    ")\n",
    "\n",
    "print(\"üìä Full-document summary table (Mean only, by Generated_File):\")\n",
    "display(df_full_table)\n",
    "\n",
    "# ============================================================\n",
    "# üß© 2Ô∏è‚É£ ELEMENT-LEVEL SUMMARY (Mean ¬± SD)\n",
    "# ============================================================\n",
    "\n",
    "elem_col = next(\n",
    "    (c for c in df_elem.columns if \"element\" in c.lower()),\n",
    "    df_elem.columns[0],\n",
    ")\n",
    "\n",
    "numeric_cols_elem = [c for c in df_elem.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "df_elem_summary = (\n",
    "    df_elem.groupby(elem_col)[numeric_cols_elem]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "flat_cols_elem = [elem_col, \"SBERT_Mean\", \"SBERT_SD\", \"ROUGE_Mean\", \"ROUGE_SD\"]\n",
    "df_elem_summary.columns = flat_cols_elem\n",
    "\n",
    "df_elem_summary[\"SBERT\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['SBERT_Mean']:.2f} ¬± {r['SBERT_SD']:.2f}\", axis=1)\n",
    "df_elem_summary[\"ROUGE\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['ROUGE_Mean']:.2f} ¬± {r['ROUGE_SD']:.2f}\", axis=1)\n",
    "\n",
    "df_elem_table = df_elem_summary[[elem_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={elem_col: \"Element\"}\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Element-level summary table (Mean ¬± SD):\")\n",
    "display(df_elem_table)\n",
    "\n",
    "# ============================================================\n",
    "# üíæ Save formatted tables\n",
    "# ============================================================\n",
    "out_full = EVAL_DIR / \"summary_full_table_mean_only.csv\"\n",
    "out_elem = EVAL_DIR / \"summary_element_table_mean_sd.csv\"\n",
    "\n",
    "df_full_table.to_csv(out_full, index=False)\n",
    "df_elem_table.to_csv(out_elem, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Saved formatted tables ‚Üí\\n‚Ä¢ {out_full}\\n‚Ä¢ {out_elem}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
